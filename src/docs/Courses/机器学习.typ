#import "/src/components/TypstTemplate/lib.typ": *

#show: project.with(
  title: "机器学习",
  lang: "zh",
)

#let TP = math.text("TP")
#let FP = math.text("FP")
#let TN = math.text("TN")
#let FN = math.text("FN")
#let ACC = math.text("ACC")
#let F1 = math.text("F1")
#let cY = math.cal("Y")
#let Ent = math.op("Ent")
#let Gain = math.op("Gain")

#let GainRatio = math.op("GainRatio")
#let Gini = math.op("Gini")
#let GiniIndex = math.op("GiniIndex")
#let cC =math.cal("C")
#info()[
  - ZJU Machine Learning 的简单笔记
    - 任课老师：赵洲
    - 因为这门课讲得不是很好（高情商），另外机器学习的内容跟当今深度学习的内容有一定 gap，所以只简单记一下*脉络与归纳*，复杂公式等均不会涉及
]

= 绪论
- 机器学习的定义
  - 关键词：经验、数据、性能
- 机器学习究竟是什么？能简述机器学习经典过程
- 机器学习能做什么?
  - 举 $1-2$ 个例子说明
- 机器学习与其它学科的关系
- 前沿机器学习期刊和会议
- 机器学习的历史和可能的未来？
  - 推理期、知识期、学习期
  - 稳健机器学习对应开放环境

= 基本术语和模型评估
== 基本术语
- 特征，又称为属性
- 属性值：特征的离散取值，或者连续取值；
- 样本维度(Dimensionality)：特征个数
- 特征张成的空间：属性空间/特征空间/输入空间
- 标记张成的空间：标记空间/输出空间
- 示例(Instance) / 样本(Sample)：一个对象的输入（比如，一个西瓜的描述）示例不含标记
- 样例(Example)：示例+标记
- 训练集 = 一组训练样例
- 测试集 = 一组测试样例
- 预测任务：根据标记的取值情况分类
  + 分类任务：标记为离散值
  + 回归任务：标记为连续值
  + 聚类任务：标记为空值，对示例进行自动分组
- 预测任务：根据标记的完整情况分类
  + （有）监督学习：所有示例都有标记
  + 无监督学习：所有示例都没有标记
  + 半监督学习：少量示例有标记，大量示例没标记
  + 噪音标记学习：标记有，但是不完全准确
  + ...
- 机器学习的根本目标 —— 泛化能力。I.I.D. 假设
- 概念学习
  - 假设空间、版本空间、归纳偏好、No Free Lunch 定理

== 模型评估
- 经验误差与过拟合
- 评估方法
  + 留出法(Hold-out)
  + 留一法(Leave-one-out)
  + 交叉验证法(Cross Validation)
  + 自助法(Bootstrapping)
- 性能度量
  - 回归任务最常用的是“均方误差”(L2 norm)
  - 分类任务最常用的是“错误率和精度”(L1 norm)
  - 构建一个混淆矩阵，计算准确率(Accuracy)，查准率或精确率(Precision)，查全率或召回率(Recall) #h(1fr)
    $
    ACC = frac(TP + TN, TP + TN + FP + FN) \
    P = frac(TP, TP + FP) \
    R = frac(TP, TP + FN) \
    F1 = frac(2 times P times R, P + R)
    $
    - 进一步，有“P-R曲线”，更常用的是 $F_1$ 度量或者一般形式 $F_beta$ 度量
    - 以 FP 为横轴、TP 为纵轴，得到 ROC 曲线；ROC 曲线下面积叫做 AUC
- 比较检验
  - 假设检验：二项检验、T-检验
- 偏差与方差
  - 泛化误差可分解为方差、偏差与噪声之和
  - 偏差-方差窘境

#info(caption: "机器学习模型引线")[
  - 基础模型：线性模型
  - 高级模型：支持向量机、统计学习方法和理论、神经网络
  #v(3pt)
  - 基础模型：决策树
  - 高级模型：Adaboost、随机森林、GBDT
  #v(3pt)
  - 基础模型：贝叶斯模型
  - 高级模型：图模型
]

= 线性模型
- 回归任务（模型：最小二乘法）
  - $X^T X$ 满秩则有 closed-form 解；若不满秩则可以加入正则项
- 二分类任务（模型：逻辑斯蒂回归、线性判别分析）
  - Logistic Regression(LR)
    - 引入 sigmoid 函数（光滑，高阶可导），建立离散标记与线性模型的关联
    - 得到类别的概率似然估计，构建极大似然目标函数，具有唯一最优解。优化求解：梯度下降、牛顿法
    - 注意 LR 模型解决的是（多）分类问题，但是其命名为回归，这与*几率*这一概念有关
    - Softmax 分类模型是最大熵模型的一个特例，LR 是 Softmax 模型在二分类时的特例
  - Linear Discriminant Analysis(LAD)
    - 寻找线性超平面，使得同类样例投影点尽可能接近，异类样例投影点尽可能远离
    - 使用类内类间散度矩阵和广义瑞利商形式设计，拉格朗日乘子法优化得到最优解(closed-from)
    - LDA 能够用于分类任务，但因为其目标函数不直接对应经验风险，性能不如直接优化经验风险的方法；因此更多用于数据降维
- 多分类任务
  - 可直接用于多分类的模型
  - 使用一对一、一对其余、多对多(use Error Correcting Output Code, ECOC)的技巧进行拆分，转化为二分类问题
  - ECOC
    - 二元码，三元码（三分类，多个停用类）
    - 编码：对 $N$ 个类别做 $M$ 次二类划分，即 $M$ 个二分类任务，各个类别长度为 $M$ 的编码
    - 解码：测试样本交给 $M$ 个二分类器，得到长度为 $M$ 的编码预测
    - ECOC 编码对分类器错误有容忍和修正能力，编码越长、纠错能力越强
    - 最优 ECOC
      - 要求：行分离，任意两个类别之间的 codeword 距离应该足够大；列分离，任意两个分类器 $f_i$, $f_j$ 的输出应相互独立，无关联（编码距离和反码距离足够大）
      - 当类别数满足 $3 =< k =< 7$，原论文给出一个构造长为 $2^(k-1)-1$ 的海明 ECOC 的方法。第一行全 $1$；第二行 $2^(k-2)$ of $0$, $2^(k-2)-1$ of $1$；第三行 $2^(k-3)$ of $0$, $2^(k-3)$ of $1$, $2^(k-3)$ of $0$, $2^(k-3)-1$ of $1$；以此类推，第 $i$ 行 $2^(k-i)$ of $0$, $2^(k-i)$ 个 $1$ 然后重复
    #fig("/public/assets/Courses/ML/2024-11-01-11-22-35.png")
- 类别不平衡任务
  - 再缩放方法(rescaling method)
    - 欠采样(under sampling): 去除一些反例使正反例数目接近(EasyEnsemble)
    - 过采样(over sampling): 增加一些正例使正反例数目接近(SMOTE)
    - 阈值移动(threshold-moving)

= 决策树
- 了解决策树基本流程
- 决策树算法的关键：划分选择
  - 信息增益(ID3)或增益率(C4.5)：使用信息熵概念，越小越纯 #h(1fr)
  $
  Ent(D) = - sum_(k=1)^cY p_k log_2 p_k \
  Gain(D, a) = Ent(D) - sum_(v=1)^V frac(|D^v|, |D|) Ent(D^v) \
  GainRatio(D, a) = Gain(D, a) / (- sum_(v=1)^V frac(|D^v|, |D|) log_2 frac(|D^v|, |D|))
  $
  - 基尼指数：使用基尼值概念，越小越纯
  $
  Gini(D) = sum_(k=1)^cY sum_(k'!=k) p_k p_k' = 1 - sum_(k=1)^cY p_k^2 \
  GiniIndex(D, a) = sum_(v=1)^V frac(|D^v|, |D|) Gini(D^v)
  $
- 克服过拟合的问题：剪枝处理
  - 预剪枝（边建树，边剪枝），在验证集上精度提高才划分
    - 降低过拟合风险；显著减少训练时间和测试时间开销
    - 有导致欠拟合的风险（本质基于贪心禁止某些分支展开）
  - 后剪枝（先建树，后剪枝）
    - 保留更多分支，欠拟合风险小；泛化性能往往优于预剪枝
    - 训练时间开销大
- 处理多种类型数据：连续与缺失值
  - 决策树只能处理离散属性，因此*连续属性离散化*（二分法）
    - 样本集 $D$ 中连续属性 $a$ 出现 $n$ 个不同的取值，以它们的中点作为 $n-1$ 个划分点，选出最优
    - 若当前结点划分属性是连续的，该属性还可作为其后代结点的划分属性
  - 缺失值处理，如果仅使用无缺失样本进行学习，是对数据信息极大的浪费
    - 在属性缺失的情况下，如何选择划分属性？
      - 跟传统决策树一致，但只在完整样本（子集）中计算信息增益，最终结果乘以 $rho$
    - 给定划分属性，若样本在该属性上缺失值，如何对该样本划分？
      -为每个样本赋予“权重”概念，正常样本权重为 $1$；而缺失属性样本给每个子节点都划分一份，但样本权值按照子节点概率分配
- 决策树的变体：多变量决策树
  - 单变量决策树的非叶节点的划分轴是单一属性（分类边界与轴平行）
  - 多变量决策树的非叶节点的划分轴是多个属性的线性组合（或者说，每个非叶节点是 $sum_(i=1)^d w_i x_i = t$ 的线性分类器，分类边界是一个超平面）

= 神经网络
- 神经网络历史
  - *第一阶段*：1943 年 M-P 模型，1949 年 Hebbian 学习规则，1958 年感知机网络，1960 年自适应线性神经元和最小均方学习算法，1969 年 《Perceptrons》 指出“单层神经网路不能解决非线性问题，多层网络的训练算法尚无希望” —— 神经网络进入低谷
  - *第二阶段*：1982 年 Hopfield 网络，1986 年 BP 算法，1987 年第一届神经网络国际会议(ICNN)。90年代初，伴随统计学习理论和 SVM 的兴起，神经网络由于可解释性弱，试错性强，难以训练，再次进入低谷
  - *第三阶段*：2006 年 Hinton 提出深度信念网络(DBN)，2012 年 AlexNet 在 ImageNet 上大获成功。深度学习进入黄金时代
  - *第四阶段*：我个人认为大模型、多模态时代可以算作深度学习的第四阶段
- 神经元模型
  - 略
- 感知机与多层网络
  - 单层感知机只能解决线性可分问题，多层感知机能以任意精度逼近任意复杂度的连续函数
- 误差反向传播算法
  - 标准、累计
- 全局最小与局部最小，如何跳出局部最小
  - 随机初始化
  - 模拟退火
  - 随机梯度下降
  - 遗传算法(GA)
    - 这个我自己搜了下，是跟 BP 算法并列的一个东西，模拟自然界对参数进行突变和选择。虽然也可以 GPU 加速，但效率上可能还是差了点，以及它在本身就很玄学的深度学习里又加了一层玄学，可解释性更差了，所以大家都不太用
- 其他常见神经网络
  - 要求不高，但还是了解一下
- 深度学习
- 小结

== 其他常见神经网络
- RBF 网络，因为之前在哪里看到过这玩意儿，多写一点
  - 单隐藏层神经网络（或者说输入隐藏输出三层），每个神经元为一个径向基函数 $rho(bx,bc_i)$，常用的如高斯径向基函数 $rho(bx,bc_i)=exp(- beta_i norm(bx-bc_i)^2)$
  $ phi(bx) = sum_(i=1)^q w_i rho(bx,bc_i) $
  - 个人觉得本质上其实跟单层 MLP 没啥区别（限制深度、宽度特化版），只是激活函数变成了径向基函数，把输入映射到高维空间再线性组合得到输出。具有足够多隐层神经元的 RBF 网络能以任意精度逼近任意连续函数
  - 通常用两步法训练参数：1. 用随机采样、聚类等方法确定神经元中心 $bc_i$；2. 用 BP 算法等确定参数 $w_i, beta_i$
  - RBF 说是拟合能力比 BP 神经网络（应该是指同级别的 MLP）强，但从这么多年都没啥人用来看，肯定有它的局限，比如，深度只有一层。当然，不是不能做深，但这又回到梯度消失爆炸的经典问题上了（激活函数导致的）。从这个角度，RBF 说到底也就只是一个特殊点的带参数的激活函数罢了，而从如今越来越趋向于简单一个 ReLU 即可的趋势来看，就更没必要用 RBF 了
- ART 网络
  - ART 网络是竞争学习的一个代表（竞争型学习是一种无监督学习策略，网络的输出神经元相互竞争，只有一个胜者被激活）
  - 网络由比较层、识别层、识别阈值、重置模块构成。其中比较层负责接收输入样本，并将其传递给识别层神经元；识别层每个神经元对应一个模式类，通过计算输入向量与每个模式类代表向量之间的距离来竞争识别输入样本；这个最小的相似度如果大于识别阈值，就归入这一类并更新权重；否则重置模块以它增加一个新的神经元（模式类动态增长）
  - ART 较好的解决了竞争学习中的“可塑性-稳定性窘境”，即神经网络要有学习新知识能力的同时保持对旧知识的记忆；ART 网络可以增量学习或在线学习
- SOM 网络
  - SOM 网络也属于竞争学习
    - 网络中的输出层神经元以矩阵方式排列在二维空间中，拥有各自的权值向量，以此确定对输入向量的获胜神经元
    - 也就是将高维输入映射到低维空间（二维空间坐标），保持了输入数据在高维空间的拓扑结构（高维空间中相似样本点在网络输出后也是邻近的）
- Cascaded 网络
  - 不仅利用训练样本优化连接权值，阈值参数，将网络的结构也当做学习的目标之一（在训练过程中找到适合数据的网络结构）
  - 级联：一开始网络只有输入层和输出层（最小拓扑结构），随着训练进行逐渐加入新的神经元，从而创建起层级结构。当候选神经元加入时，它跟所有隐藏神经元和输入神经元连虚线（原本的网络权重视为实线），并且不跟输出神经元相连
  - 相关：接下来先只训练虚线，相关是指通过最大化候选神经元的输出与网络误差之间的 correlation（换句话说，你可以暂时不降低误差，但你得跟误差非常相关）。这一步训练好后，把候选神经元真正加入网络，把输出边连上，再次训练整个网络
- Elman 网络
  - Elman 网络是最常见的递归神经网络之一，隐藏层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起作为下一时刻隐藏层神经元的输入
- Boltzmann 机
  - Boltzmann 机是一种能量模型网络，其能量函数由神经元的状态（布尔型，只能激活和抑制两种状态）决定，通过最小化能量函数来学习网络参数（达到 Boltzmann 分布）
  - 分为显层（数据的输入输出）和隐层（数据的内在表达）。标准的 Boltzmann 机是全连接的，复杂度很高，难以解决现实任务；通常使用受限 Boltzmann 机(RBM)来简化，仅保留显层和隐层之间的连接，化为二部图
  - 使用对比散度(CD)算法来训练参数（连接权重 $w$ 和影响激活阈值的偏置 $b$）
- 分类：前馈网络、反馈网络和循环、递归网络
  - 前馈网络(Feedforward Network)，是一种最简单的神经网络。各神经元分层排列，每个神经元只与前一层的神经元相连，接收前一层的输出，并输出给下一层，层间没有联系。包括 BP 神经网络、RBF 网络等
  - 至于反馈网络和递归循环网络的分类就乱了起来，毕竟本质上循环、递归也是一种反馈，但是我在网上看到的资料又只说反馈网络是 Hopfield 网络
  - 反馈网络(Feedback Network)，其实就是 Hopfield 网络（也是能量模型网络），当给网络一组初始值时，网络通过自行运行而最终收敛到平衡点（网络能量最低点）上
  - 循环网络(Recurrent Network)和递归网络(Recursive Network)，前者包括经典 RNN, LSTM, GRU 等；后者是前者到树形式的推广（递归神经网络父节点仅与一个子节点连接时等价于全连接循环神经网络），最常用的是 Elman 网络
    - 二者的缩写均为 RNN，极易混淆，而事实上后者好像就被前者盖过了（
- 我的一个感觉是，这些所谓“常见神经网络”都设计感太强，不适合做深做大，不适合深度学习参数量当道的理念，因此现在都没什么人用了，权当拓展知识罢

= 支持向量机
- 间隔与支持向量：支持向量机的"最大间隔”思想
- 对偶问题：对偶问题及其解的稀疏性
- 核函数：通过向高维空间映射解决线性不可分的问题
- 软间隔与正则化：引入"软间隔"缓解特征空间中线性不可分的问题
- 支持向量回归：将支持向量的思想应用到回归问题上得到支持向量回归
- 核方法：将核方法推广到其他学习模型
- 《数据建模与分析》重点学过辣，过！（其实是懒得记了）

= 贝叶斯分类器
- 掌握贝叶斯决策论
  - 给定 $N$ 个类别，令 $la_ij$ 代表将属于第 $j$ 类的样本 $bx$ 误分类为第 $i$ 类所产生的损失，基于后验概率将样本 $bx$ 分到第 $i$ 类的条件风险为
    $ R(ci|bx) = sum_(j=1)^N la_ij P(c_j|bx) $
  - 贝叶斯判定准则(Bayes decision rule):
    $ h^*(bx) = argmin_(c in cY) R(c|bx) $
    - $h^*$ 称为贝叶斯最优分类器(Bayes optimal classifier)，其总体风险称为贝叶斯风险(Bayes risk)，反映了学习性能的理论上限
    - 注意：贝叶斯分类器 $!=$ 贝叶斯学习，后者是更广泛的学习概念
  - 后验概率 $P(bc|bx)$ 在现实中难以直接获得，机器学习需要根据有限训练样本尽可能准确地估计后验概率，有两种基本策略
    + 判别式(discriminative): 直接对 $P(bc|bx)$ 建模，代表：决策树、BP 神经网络、SVM
    + 生成式(generative): 对联合概率密度 $P(bx, bc)$ 建模，然后通过贝叶斯公式计算后验概率，代表：贝叶斯分类器（如朴素贝叶斯）
- 熟悉极大似然估计
  - 先假设某种概率分布形式，再基于训练样例对分布的参数进行估计。连乘易造成下溢，通常取对数似然函数
  - 结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实分布
- 熟悉朴素贝叶斯（拉普拉斯修正）
  $ P(c|bx) prop P(c) Pi_(i=1)^d P(x_i|c) $
  - 其中 $bx$ 为具有 $d$ 个属性的样本，$x_i$ 为 $bx$ 在第 $i$ 个属性上的取值，$c$ 为类别
  - 《数据建模与分析》重点学过辣，略
  - 具体使用时：
    + 若对预测速度要求高 $->$ 预计算所有概率估值，使用时“查表”
    + 若数据更替频繁 $->$ 任数据更替不进行训练，收到预测请求时再估值(lazy learning)
    + 若数据不断增加 $->$ 基于现有估值，对新样本涉及的慨率估值进行修正(incremental learning)
- 掌握半朴素贝叶斯
  - 朴素贝叶斯的“独立性假设”现实中难以成立，适当考虑一部分属性间的相互依赖信息，最常用的是独依赖估计(One-Dependent Estimator, ODE)，关键在于如何确定每个属性的父属性
  $ P(c|bx) prop P(c) Pi_(i=1)^d P(x_i|c, p a_i) $
  - 其中 $p a_i$ 为属性 $x_i$ 的父属性，可以看作是在做贝叶斯分类前的超参，下面我们有几种确定它的方法：
  - SPODE(Super-Parent ODE): 假设所有属性都依赖于同一属性，称为“超父”，然后通过交叉验证等方法来确定
  - TAN(Tree Augmented naive Bayes): 以属性间的条件互信息(conditional mutual information)为边的权重来构建完全图，再利用最大带权生成树算法，仅保留强相关属性间的依赖性
  - AODE(Averaged One-Dependent Estimator): 尝试将每个属性作为超父构建 SPODE，将有足够训练数据支撑（大于阈值）的 SPODE 集成起来作为最终结果
    $
    P(c|bx) prop sum_(i=1, abs(D_x_i) >= m')^d P(c,x_i) P_(j=1)^d P(x_j|c, x_i)
    $
    - 其中 $D_x_i$ 是在第 $i$ 个属性上取值为 $x_i$ 的样本集，$m'$ 为阈值常数
    $ hat(P)(c,x_i) = frac(abs(D_(c,x_i))+1,abs(D)+N_i), ~~~ hat(P) (x_j|c,x_i) = frac(abs(D_(c,x_i,x_j))+1,abs(D_(c,x_i))+N_j) $
    - 其中 $D_(c,x_i,x_j)$ 是类别为 $c$ 且第 $i$ 个属性取值为 $x_i$ 且第 $j$ 个属性取值为 $x_j$ 的样本集，$N_i$ 为第 $i$ 个属性可能取值的个数
- 掌握贝叶斯网
  - 进一步考虑属性间的高阶依赖，最简单的做法是 ODE $->$ KDE，但计算复杂度指数级增加，考虑高阶依赖需要其它办法
  - 贝叶斯网(Bayesian Network)，亦称信念网(Brief Network)，是一种有向无环图(DAG)，图中每个节点代表一个属性，节点之间的有向边代表属性间的依赖关系
  - 给定父结点集，贝叶斯网假设每个属性与其非后裔属性独立
  #fig("/public/assets//Courses/ML/2024-10-31-20-46-11.png", width: 60%)
  - 贝叶斯网络中三变量典型依赖关系
  #fig("/public/assets//Courses/ML/2024-10-31-21-07-31.png", width: 60%)
  - 利用“道德图”分析条件独立性
    - 将贝叶斯网络转化为无向图，若 $x$ 和 $y$ 能被 $bz$ 分成两个联通分支，则 $x$ 和 $y$ 在给定 $bz$ 的条件下独立，即 $x perp y | bz$
  - 在概率图模型中，有向图模型 $->$ 贝叶斯网和马尔科夫链，无向图模型 $->$ 马尔科夫网
    - 马尔科夫网不是很懂。但是马尔科夫链跟贝叶斯网络非常像，前者是后者的特例，后者是前者的推广：马尔科夫链中，后代结点只依赖于父结点，与后裔和更先代无关
  - 贝叶斯网络的训练（学习）
    - 评分函数的第一项是计算编码贝叶斯网 $B$ 所需的字节数，第二项是计算 $B$ 所对应的概率分布 $P_B$ 需要多少字节来描述 $D$（对数似然，对一个训练数据上的概率分布，用哈夫曼编码之类使经常出现的样本有更短编码，从而建立概率分布到编码长度的映射）
    #fig("/public/assets//Courses/ML/2024-10-31-21-30-46.png", width: 80%)
    - 搜索最优贝叶斯网络结构是 NP 难问题，一般采用贪心算法或限制网络为树形结构等方法来降低求解难度
  - 贝叶斯网络的推断
    - 查询(query)贝叶斯网络，基于已知属性变量的观测值（证据，evidence），推断(inference)其他属性变量的取值
    - 不幸的是，即使网络已经建好，精确推断也是 NP 难问题。为了在有限时间内求得近似解，常常降低精度要求，采用近似推断方法，如*吉布斯采样*、*变分推断*等
    - 吉布斯采样：待查询变量 $bold(Q)={Q_1,Q_2,...,Q_n}$，证据变量 $bold(E)={E_1,E_2,...,E_k}$，查询的目标值 $bold(q)={q_1,q_2,...,q_n}$，证据变量取值 $bold(e)={e_1,e_2,...,e_k}$，求解后验概率 $P(bold(Q)=bold(q)|bold(E)=bold(e))$
      + 先随机对 $bold(Q)$ 赋初值（其它变量与证据 $bold(E)=bold(e)$ 一致）
      + 逐个考察每个非证据变量 $Q_i$：假定所有其他属性取当前值，从网络推断出采样概率，然后根据该概率采样
        - 即在贝叶斯网所有变量的联合状态空间与证据取值一致的子空间中“随机游走”，每一步仅依赖上一步状态，属于马尔科夫链，最后一般收敛到平稳分布
      + 执行 $T$ 次上述步骤，有 $n_q$ 次取到 $bold(q)$，则 $P(bold(Q)=bold(q)|bold(E)=bold(e)) approx n_q/T$
    - 变分推断，基于 EM 算法，看不懂
- 了解 EM 算法
  - 《数据建模与分析》重点学过辣，略

= 集成学习
- 集成学习(ensemble learning)通过构建并结合多个学习器来提升性能
  - 个体学习器的“准确性”和“多样性”本身就存在冲突，如何产生“好而不同”的个体学习器是集成学习研究的核心
  - 集成学习大致可分为两大类: 串行(Boosting) vs 并行(Bagging)
- Boosting 最著名的代表是 Adaboost
  - 问题的提出：只要找到一个比随机猜测略好的弱学习算法就可以直接将其提升为强学习算法，而不必直接去找很难获得的强学习算法。两个核心问题：(1) 怎样获得不同的弱分类器？(2) 怎样组合弱分类器？
  - 对于前者，有以下几种方法：
    - 使用不同的弱学习算法得到不同基本学习器（参数估计、非参数估计……）
    - 使用相同的弱学习算法，但用不同的参数（K-Means 不同的 $K$，神经网络不同的隐含层……）
    - 相同输入对象的不同表示凸显事物不同的特征
    - 使用不同的训练集 $->$ 装袋(bagging)，提升(boosting)
  - 对 Adaboost，每一轮如何改变训练数据的权值或概率分布？被前一轮弱分类器错误分类样本的权值提高（数据集每个样本都赋予一个权值）；如何将弱分类器组合成一个强分类器？加权多数表决，加大分类误差率小的弱分类器的权值
  #algo(title: [*Algorithm* of *AdaBoost*])[
    - 输入：二分类训练数据集 $T = {(x1,y1), ..., (xn,yn)}, x_i in cal(X) subset RR^n, yi in cal(Y) = {-1,+1}$
    - 输出：最终分类器 $G(x)$
    + 1. 初始化训练数据的权值分布 $D_1 = (w_11, ..., w_(1N)), w_(1i) = 1/N$
    + 2. 对 $m = 1,2,...,M$
      + a. 在权值 $D_m$ 下训练数据集，得到弱分类器 $G_m (x) : cal(X) -> {-1,+1}$
      + b. 计算 $G_m (x)$ 的训练误差：$e_m = sum_(i=1)^N P(G_m (x_i) != y_i) = sum_(i=1)^N w_(m i) I(G_m (x_i) != y_i)$
      + c. 计算弱分类器 $G_m (x)$ 的系数：$al_m = 1/2 log (1-e_m)/e_m$ #redt[$=>$ 思考为什么]
      + d. 更新训练数据集的权值分布 $D_(m+1) = (w_(m+1 1), ..., w_(m+1 N))$
        $ w_(m+1, i) = frac(w_(m i) exp(-al_m y_i G_m (x_i)), sum_(j=1)^N w_(m j) exp(-al_m y_j G_m (x_j))) $
    + 3. 构建弱分类器的线性组合，并以其符号作为最终结果 $G(x) = "sign"(sum_(m=1)^M al_m G_m (x))$
  ]
  - 说明
    + 步骤 c，$al_m = 1/2 log (1-e_m)/e_m$，当 $e_m =< 1/2$ 时，$al_m >= 0$。即误分类小于一半（优于随机）时，对最终分类器贡献为正
    + 步骤 d，更新后的权值分布，误分类样本的权值相对争取样本增大 $e^(2al_m)=frac(e_m, 1-e_m)$ 倍，有点类似学习率衰减
  - Adaboost 的 $al$ 是怎么来的？为了保证最终分类器的训练误差界：
    $ 1/N sum_(i=1)^N I(G(x_i)!=yi) =< 1/N sum_(i=1)^N exp(-y_i f(x_i)) = underbrace(Pi_(m=1)^M Z_m = Pi_(i=1)^M 2 sqrt(e_m (1-e_m)), ["use equation of" al]) =< exp(-2 sum_(i=1)^M (1/2-e_m)^2) $
  - Adaboost 本质是个以“加法模型”为模型，以“指数损失函数”为损失函数，以“前向分步算法的二分类学习算法”为学习算法的方法。可以看到它的学习器是不断“提升”的，互相之间有强依赖关系
- Bagging 与随机森林
  - 个体学习器不存在强依赖关系、并行化生成、自助采样法
  - 我们可以用自助采样法得到 $T$ 个含 $m$ 个训练样本的采样集，基于每个采样集训练出一个基学习器，这就是 Bagging 的基本流程。在对预测输出进行结合时，通常对分类任务使用简单投票法（若收到同样票数，可以随机选一个，也可以进一步按照置信度选择），对回归任务使用简单平均法
  - 随机森林(Random Forest, RF)是 bagging 的一个扩展变种：采样的随机性、属性选择的随机性

= 聚类
- 聚类任务
  - 将数据样本划分为若干个通常不相交的“簇”(cluster)。不相交的簇 —— 硬聚类；可相交的簇 —— 软聚类
- 性能度量
  - 基本想法：“簇内相似度”(intra-cluster similarity)高，且“簇间相似度”(inter-cluster similarity)低
  - *外部指标(external index)*：将聚类结果与某个“参考模型”(reference model)进行比较，如 Jaccard 系数，FM 指数，Rand 指数
    - 数据集 $D={x1,x2,x_m}$
  - *内部指标(internal index)*：直接考察聚类结果，无参考模型，如 DB 指数，Dunn 指数
- 距离计算
  - 能够说出距离计算对聚类的意义
- 原型聚类
  - 能够说出思路和代表性算法
- 密度聚类
  - 能够说出思路和代表性算法
- 层次聚类
  - 能够说出思路和代表性算法

= EM 算法
- 《数据建模与分析》重点学过辣，略

= 降维与度量学习
- k-近邻学习
  - 知道怎么实现，以及知道它重要的理论性质和现实不可行之原因
- 低维嵌入
  - 知道 MDS 的思路和能够回答为什么
- 流形学习
  - 知道 ISOMAP 和 LLE 是怎么实现（核心思路）
- 度量学习
  - 知道度量学习的主要思路 —— 学习参数化马氏距离





= 强化学习





= 深度学习前沿
== Transformer

== Diffusion Model

== Mamba
