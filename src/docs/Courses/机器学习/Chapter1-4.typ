#import "/src/components/TypstTemplate/lib.typ": *

#show: project.with(
  title: "机器学习",
  lang: "zh",
)

#let NP = math.text("NP")
#let TP = math.text("TP")
#let FP = math.text("FP")
#let TN = math.text("TN")
#let FN = math.text("FN")
#let ACC = math.text("ACC")
#let F1 = math.text("F1")
#let var = math.op("var")
#let bias = math.text("bias")

#info()[
  - ZJU Machine Learning 和西瓜书《机器学习 —— 周志华》的简单笔记
    - 任课老师：赵洲
    - 因为这门课讲得不是很好（高情商），西瓜书本身也写得晦涩难懂，另外机器学习的内容跟当今深度学习的内容有一定 gap，所以只简单记一下*脉络与归纳*，不会记录太复杂的公式推导
]

#note(caption: "机器学习在整个人工智能中的位置如何？")[
  在正式学习内容之前，先对我们要学习的内容做一个定位有助于梳理知识体系。

  - *知识库方法 Knowledge Base*
    - 将关于世界的知识用形式化的语言进行硬编码。计算机使用逻辑推理规则来自动理解这些形式化语言中的声明
    - 差不多就是我们之前学习过的《人工智能逻辑》里的内容
    - 知识库方法遇到的困难是难以设计出足够复杂的形式化规则来精确地描述世界
      - 举个例子，最著名的知识库项目 Cyc 不能理解人在刮胡子时是否仍是一个人：它知道人体的构成不含有电器零件，但由于人拿着剃须刀，就认为实体含有电器部件
  - *机器学习方法 Machine Learning*
    - 由人将数据处理成结构化的形式，而后系统具备自己获取知识的能力，能够从原始数据中用特定算法提取模式
    - 换句话说，所谓“机器学习”就是用“模型”（“学习算法”）从“数据”中提取“经验”
      - 狭义的机器学习方法就是指主要使用数理统计方法作为学习算法，这也是这本书大概所处的位置。但更广义一点，机器学习或许可以包容之后的几个概念
    - 看着似乎很美好，但“数据”往往需要经过人工的特征工程处理。狭义的特征工程指数据清洗（包括缺失异常值处理、特征选择、维度压缩等），更广义的则是指让数据有更好的表达能力
  - *表征学习 Representation Learning*
    - 用机器学习来发掘表示本身，学习到的表示往往比手动设计的好
    - 例如，深度学习就是一种表征学习方法，它通过多层神经网络来学习数据的表示
      - 从表征学习的角度来看，自编码器架构的出现就显得非常自然：自编码器架构由编码器函数和解码器函数组成，编码器将输入数据映射到表示空间，解码器将表示空间映射回原始数据空间。期望是输入数据经过编解码器后尽可能多地保留信息，同时希望新的表示有各种好的特性
      - 另外，深度学习深到一定程度就是现在大热的大模型了
]

= 绪论
- 机器学习的定义
  - 关键词：经验、数据、性能
- 机器学习究竟是什么？能简述机器学习经典过程
- 机器学习能做什么?
  - 举 $1-2$ 个例子说明
- 机器学习与其它学科的关系
- 前沿机器学习期刊和会议
- 机器学习的历史和可能的未来？
  - 推理期、知识期、学习期
  - 稳健机器学习对应开放环境
#hline()
- 该部分从略

= 基本术语和模型评估
== 基本术语
- 特征，又称为属性
- 属性值：特征的离散取值，或者连续取值；
- 样本维度(Dimensionality)：特征个数
- 特征张成的空间：属性空间/特征空间/输入空间
- 标记张成的空间：标记空间/输出空间
- 示例(Instance) / 样本(Sample)：一个对象的输入（比如，一个西瓜的描述）示例不含标记
- 样例(Example)：示例+标记
- 训练集 = 一组训练样例
- 测试集 = 一组测试样例
- 预测任务：根据标记的取值情况分类
  + 分类任务：标记为离散值
  + 回归任务：标记为连续值
  + 聚类任务：标记为空值，对示例进行自动分组
- 预测任务：根据标记的完整情况分类
  + *（有）监督学习*：所有示例都有标记
  + *无监督学习*：所有示例都没有标记
  + *半监督学习*：少量示例有标记，大量示例没标记
  + 噪音标记学习：标记有，但是不完全准确
  + ...
- 机器学习的根本目标 —— 泛化能力。I.I.D. 假设
- 概念学习
  - 假设空间：所有可能的概念，或者说每个属性取值的组合
  - 版本空间：假设空间的子集，与训练集一致的假设集合
  - 归纳偏好：学习过程中对某种类型假设的偏好称作归纳偏好
  - No Free Lunch 定理
    - 具体公式不用记，总之就是脱离实际问题谈算法就是耍流氓
    - 但话又说回来，就像高斯概率分布一样，哪种问题最常见又是有一定规律可循的
  - 机器学习技术是“大胆假设”和“小心求证”的折衷
    - 大胆假设：*样本维度越高，假设空间越大，归纳偏好越重要*
    - 小心求证：通过训练集和测试集来验证假设的泛化能力

== 模型评估
=== 经验误差与过拟合
- 训练集上的误差称为 “训练误差” 或 “经验误差”，在新样本上的误差称为 “泛化误差”，我们无法得知后者，只能最小化前者
- 欠拟合与过拟合
  - 概念略
  - 过拟合只能*缓解*而无法彻底解决，可以这样理解：
    - 机器学习面临的问题至少是 NP 难，而有效的学习算法必然在多项式时间内完成
    - 如果能彻底避免过拟合，通过经验误差最小化就获得最优解，相当于构造性地证明了 $P=NP$
    - 因此只要相信 $P!=NP$，过拟合就无法完全避免

=== 评估方法
+ *留一法(Leave-one-out)*
  - 每次留下一个样本作为测试集，剩下样本作为训练集，做 $N$ 次训练，直到*每一个样本都被用作过一次测试集*
+ *留出法(Hold-out)*
  - 随机 or 保证*数据分布一致性*的前提下，将数据集划分为训练和测试集，常用比例为 $2:1 wave 4:1$
  - `from sklearn.model_selection import train_test_split` 加上 `stratify=label` 参数则会根据 label 的分布比例划分，否则随机划分
  - 但在考试的时候，往往会假设分布一致（不然随机没法考）
+ *交叉验证法(Cross Validation)*
  - 随机将数据集划分为 $k$ 个大小相等的子集，每次取 $k-1$ 个子集作为训练集，剩下的一个子集作为测试集（做 $k$ 次训练）
  - `from sklearn.model_selection import KFold` 是随机划分，若要保证分布一致，需使用*分层 K 折交叉验证* `StratifiedKFold`
  - 但在考试的时候，往往没有这二者的区分，默认就是分层（不然随机没法考）
+ *自助法(Bootstrapping)*
  - 从数据集 $D$ 中有放回地抽取 $N$ 个样本，作为训练集 $D'$；剩下的样本作为测试集
  - 一个样本始终不被采样到的概率是 $lim_(N -> infty) (1-1/N)^N = 1/e approx 0.368$
  - 自助法对数据集很小、难以有效划分训练 / 测试集时很有用

== 性能度量
- 回归任务最常用的是“均方误差”(L2 norm)
- 分类任务最常用的是“错误率和精度”(L1 norm)
- 构建一个*混淆矩阵*，计算准确率 (Accuracy)，查准率或精确率 (Precision)，查全率或召回率 (Recall)
  #tbl(
    columns: 3,
    [],[预测正例],[预测反例],
    [真实正例],[TP],[FN],
    [真实反例],[FP],[TN]
  )
  $
  ACC = frac(TP + TN, TP + TN + FP + FN) ~~~~ "所有里面有多少是对的" \
  P = frac(TP, TP + FP) ~~~~ "预测的正例有多少是对的" \
  R = frac(TP, TP + FN) ~~~~ "对的里面有多少被预测出来" \
  F1 = frac(2 times P times R, P + R) = frac(2 times TP, N + TP - TN)
  $
  - 不过一般来说，模型预测出的结果并非二值化，而是有一个置信度，可以据此对测试样本排序，逐个把样本作为正类计算度量曲线
    - P-R 曲线：P 为纵轴、R 为横轴，$y=x$ 上的是平衡点
    - 更常用的是 $F 1$ 度量或者一般形式 $F_beta$ 度量
  - 有时会有多个二分类混淆矩阵（比如多次训练或交叉验证），那么估算模型性能有两种
    - 宏观 (macro)：对每个混淆矩阵计算性能度量，然后求平均
    - 微观 (micro)：将所有混淆矩阵合并，然后计算性能度量
    - 由此得到上述性能度量的宏观和微观形式（感觉宏微观跟常规或者说个人理解有点相反，但这里就是这么定义）
  - 对模型预测出的置信度应用不同的阈值，可以得到不同的结果
    - 以 FP 为横轴、TP 为纵轴，得到 ROC 曲线；ROC 曲线下面积叫做 AUC
- 代价敏感错误率，跟混淆矩阵一样构建代价矩阵
  #tbl(
    columns: 3,
    [],[预测第 $0$ 类],[预测第 $1$ 类],
    [第 $0$ 类],[],[$"cost"_01$],
    [第 $1$ 类],[$"cost"_10$],[]
  )
  - 从最小化犯错次数变成最小化总体代价

=== 比较检验
- 虽然我们有了上述度量，但是由于 测试性能并不等于泛化性能、测试性能随着测试集而变化、很多算法本身具有随机性 等原因，直接用某种评估方法再用某种性能度量然后比大小并不可取
- 假设检验的目的是推断出：若在测试集上观察到学习器 $A$ 比 $B$ 好，则 $A$ 的泛化性能是否在统计意义上优于 $B$，以及这个结论的把握有多大。这一节默认以错误率为性能度量
- 假设检验
  - 二项检验
    - 在测试集上的错误率为 $hat(ep)$，这并不等于泛化错误率 $ep$，但如果测试样本是从样本总体分布中独立采样而来，二者应该是接近的，即 $P(hat(ep);ep)$ 在 $ep=hat(ep)$ 处取得最大，这符合二项分布
    - 一般地，考虑希望让泛化误差*小于*一个阈值 $ep_0$ 的话，则测试集误差也应该小于某个临界值（这里考虑的是单边检验的拒绝域形式），而这个临界值我们也用一个概率 $al$ 来调控
      $ hat(ep) < overline(ep) = max ep, st sum_(i=ep_0 times m + 1)^m vec(m, i) ep^i (1-ep)^(m-i) < al $
      - 则在 $al$ 的显著度下，假设不能被拒绝，也即能以 $1-al$ 的置信度认为，模型的泛化错误率不大于 $ep_0$
  - T-检验与交叉验证 T-检验
    - 如果通过多次重复留出法或是交叉验证法进行多次实验，会得到多个测试错误率，这些错误具有均值 $mu$ 和方差 $si$，可以将其看作所谓 $t$ 分布
      $ ta_t = frac(sqrt(k) (mu - ep_0), si) $
    - 像上面一样我们也能用单边检验的形式来做，但这里采用双边(two-tailed)假设，考虑泛化误差 $ep$ *等于* $ep_0$ 的可能性
      - 若临界范围 $mu-ep_0$ 落在上述 $t$ 分布在一段根据显著度 $al$ 面积来决定的 $[t_(-al/2), t_(al/2)]$ 范围内，则假设不能被拒绝（即，$ep=ep_0$ 的置信度为 $1-al$）
    - 特别地如果用的是交叉验证法，可以用成对的方法去做 paired t-test，这里略过

=== 偏差与方差
- 即使训练集来自同一个分布，学习算法在上面得到的结果也会不同。以使用均方误差的回归任务为例
  - 学习算法的期望预测
    $ of(bx) = EE_D [f(bx;D)] $
  - 同样本数量的不同训练集产生的方差
    $ var(bx) = EE_D [(f(bx;D) - of(bx))^2] $
  - 假设噪声满足期望为 $0$ 的分布，其方差为：（$y_D$ 是 $bx$ 在数据集中受噪声影响的标记，$y$ 为 $bx$ 的真实标记）
    $ ep^2 = EE_D [(y_D - y)^2] $
  - 期望输出与真实标记的偏差
    $ bias^2 (bx) = (of(bx) - y)^2 $
- 一长串猛如虎的推导之后，得出泛化误差可分解为方差、偏差与噪声之和
  $ EE_D [(f(bx;D) - y)^2] = bias^2 (bx) + var(bx) + ep^2 $
  - 偏差刻画了学习算法本身的拟合能力，方差刻画了数据扰动造成的影响，噪声则是学习问题本身的难度
- 偏差-方差窘境
  - 一般来说，偏差与方差是有冲突的
    - 在训练不足时，*偏差*主导泛化误差率（欠拟合）
    - 随着训练程度加深，学习器拟合能力变强，*方差*逐渐主导泛化误差率，此时训练数据的轻微扰动都会导致显著变化（即过拟合）

#info(caption: "机器学习模型引线")[
  - 基础模型：线性模型
  - 高级模型：支持向量机、统计学习方法和理论、神经网络
  #v(3pt)
  - 基础模型：决策树
  - 高级模型：Adaboost、随机森林、GBDT
  #v(3pt)
  - 基础模型：贝叶斯模型
  - 高级模型：图模型
]

= 线性模型
== 线性模型引言
- 一般形式（向量）：$f(x) = w^T x + b$
- 线性模型虽然表达能力有限，但易于理解和建模（可解释性）；并且许多更为强大的非线性模型能在其基础上引入层级结构或高维映射而得
== 回归任务
- 回归任务处理连续值，如果是离散属性一般通过连续化处理（利用序关系或 one-hot 编码）
- 一元形式直接略过，多元形式
  - 把 $w$ 和 $b$ 合并到 $w$ 中化为齐次表达，把整个数据集写成矩阵 $bX$，标记写成向量 $by$
  $ f(bx) = bw dot bx, ~~~~ f(bX) = bX bw $
- 一般采用均方误差作为损失函数
  $ bw^* = argmin_bw (by - bX bw)^T (by - bX bw) $
- 模型采用最小二乘法，对上式求导即可，$bX^T bX$ 满秩则有 closed-form 解（若不满秩可以加入正则项）
  $ bw^* = (bX^T bX)^(-1) bX^T by $
- 对数线性回归与广义线性回归
  $
  y = g^(-1) (bw^T bx + b) \
  g(dot) = ln(dot)
  $

== 分类任务
- 二分类任务（模型：逻辑斯蒂回归、线性判别分析）

=== 逻辑斯蒂回归
- Logistic Regression(LR), or Logit Regression
  - 引入对数几率函数(logistic function)，建立离散标记与线性模型的关联
    $ y = frac(1, 1 + e^(-x)) $
    - 沟槽的深度学习社区把它叫做 sigmoid 函数，具有光滑、高阶可导的性质
- 得到类别的概率似然估计，构建极大似然目标函数
  $
  PiiN P(y=1|bx; bw,b)^(y_i) P(y=0|bx; bw,b)^(1-y_i) \
  L(w) = sumiN y_i (bw dot bx_i) - ln(1 + e^(bw dot bx_i))
  $
- 用梯度下降法、牛顿法求解上述目标函数的负数，得到唯一最优解 $bw^*$，那么得到的模型为
  $
  P(y=1|bx) = frac(e^(bw^T bx), 1 + e^(bw^T bx)) \
  P(y=0|bx) = frac(1, 1 + e^(bw^T bx))
  $
- 注意 LR 模型解决的是（多）分类问题，但是其命名为回归，这与*几率*或者说*对数几率*(log odds)这一概念有关
  $
  y = frac(1, 1 + e^(-(bw^T bx + b))) \
  ln frac(y,1-y) = bw^T bx + b
  $
- \*Softmax 分类模型是最大熵模型的一个特例，LR 是 Softmax 模型在二分类时的特例

=== 线性判别分析
- Linear Discriminant Analysis(LDA)
  - 基本思想：寻找线性超平面，投影到其上，使得*同类*样例投影点尽可能*接近*，*异类*样例投影点尽可能*远离*
  - 给定数据集 $D = {(bx_1, y_1), dots, (bx_m, y_m)}$，其中 $bx_i in RR^d, y_i in {0,1}$，令
    - $bX_i$ 表示第 $i$ 类样本的集合，$bmu_i$ 表示样本均值，$Sigma_i$ 表示样本协方差
    - 若将数据投影到超平面 $bw^T bx = 0$ 上，那么类的投影均值（中心）为 $bw^T bmu_i$，投影协方差为 $bw^T Sigma_i bw$
  - 以二分类为例，同类样本投影点的协方差尽可能小，即 $bw^T Sigma_0 bw + bw^T Sigma_1 bw$ 尽可能小；异类样本投影点的均值尽可能远离，即 $norm(bw^T bmu_0 - bw^T bmu_1)$ 尽可能大。从而得到优化目标
    $ J(bw) = frac(norm(bw^T bmu_0 - bw^T bmu_1)_2^2, bw^T Sigma_0 bw + bw^T Sigma_1 bw) eq.delta frac(bw^T S_b bw, bw^T S_w bw) $
- 使用类内类间散度矩阵和广义瑞利商形式设计，拉格朗日乘子法优化得到最优解(closed-from)
  $
  min_bw -bw^T S_b bw \
  s.t. ~~~~ bw^T S_w bw = 1 \
  ==> w = S_w^(-1) (bmu_0 - bmu_1)
  $
- 多分类 LDA
  - 常见实现是
    $
    max_W frac(tr(W^T S_b W), tr(W^T S_w W))
    $
  - 求解下式，把 $S_w$ 取逆就变成特征值分解问题
    $ S_b W = la S_w W $
- LDA 能够用于分类任务，但因为其目标函数不直接对应经验风险，性能不如直接优化经验风险的方法；因此更多用于数据降维
#note(caption: "总结（LDA 要会算）")[
  - $N_i$ 为第 $i$ 类样本数，$bmu$ 为所有样本的均值，然后不管几分类，算下面两个矩阵
  $
  S_w &= sumiN sum_(bx in bX_i) (bx - bmu_i) (bx - bmu_i)^T "类内散度矩阵，每个类内部计算" \
  S_b &= sumiN N_i (bmu_i - bmu) (bmu_i - bmu)^T "类间散度矩阵，对类之间计算"
  $
  - 然后，如果是二分类，直接 $w = S_w^(-1) (bmu_0 - bmu_1)$ 即可，不用特征值分解；否则多分类求 $S_w^(-1) S_b$ 的特征值分解
]

=== 多分类任务
  - 可直接用能够多分类的模型，或者使用一对一(OvO)、一对其余(OvR)、多对多（MvM，常用 Error Correcting Output Code, ECOC）的技巧进行拆分，转化为二分类问题
  - OvO
    - 拆分阶段，$N$ 个类别两两配对 $-->$ $frac(N(N-1), 2)$ 个二类任务和分类器
    - 测试阶段，$frac(N(N-1), 2)$ 个分类结果，投票以被预测最多的类为最终类别
  - OvR
    - 拆分阶段，某一个作为正例，其它为反例 $-->$ $N$ 个二类任务和分类器
    - 测试阶段，使用各分类器预测为各类的置信度来决定
    - 比较 OvO 和 OvR，前者训练的开销通常更小（只用两个类），后者的存储和测试开销更小
  - MvM, use ECOC
    - 二元码，三元码（三分类，多个停用类）
    - 编码：对 $N$ 个类别做 $M$ 次二类划分，即 $M$ 个二分类任务，各个类别长度为 $M$ 的编码
    - 解码：测试样本交给 $M$ 个二分类器，得到长为 $M$ 的编码预测，与每个类各自固有的编码比较，选取最近的类别作为预测结果
    - ECOC 编码对分类器错误有容忍和修正能力，编码越长、纠错能力越强
    - 最优 ECOC
      - 要求：行分离，任意两个类别之间的 codeword 距离应该足够大；列分离，任意两个分类器 $f_i$, $f_j$ 的输出应相互独立，无关联（编码距离和反码距离足够大）
      - 当类别数满足 $3 =< k =< 7$，原论文给出一个构造长为 $2^(k-1)-1$ 的海明 ECOC 的方法。第一行全 $1$；第二行 $2^(k-2)$ of $0$, $2^(k-2)-1$ of $1$；第三行 $2^(k-3)$ of $0$, $2^(k-3)$ of $1$, $2^(k-3)$ of $0$, $2^(k-3)-1$ of $1$；以此类推，第 $i$ 行 $2^(k-i)$ of $0$, $2^(k-i)$ 个 $1$ 然后重复
    #fig("/public/assets/Courses/ML/2024-11-01-11-22-35.png")
- 类别不平衡任务
  - 再缩放方法 (rescaling method)，如果正例远少于反例：
    - 欠采样 (under sampling)：去除一些反例使正反例数目接近 (EasyEnsemble)
    - 过采样 (over sampling)：增加一些正例使正反例数目接近 (SMOTE)
    - 阈值移动 (threshold-moving)：直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将式 $frac(y,1-y) > frac(m^+,m^-)$ 嵌入到其决策过程中
  - 这里讲得比较简单，可以看这篇文章 #link("https://zhuanlan.zhihu.com/p/94599093")[类不平衡问题 Class imbalance]，不仅详细讲述了这三种方法，还实践了一波采样的无偏性
