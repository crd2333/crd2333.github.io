#import "/src/components/TypstTemplate/lib.typ": *

#show: project.with(
  title: "机器学习",
  lang: "zh",
)

#let cY = math.cal("Y")
#let Ent = math.op("Ent")
#let Gain = math.op("Gain")
#let GainRatio = math.op("GainRatio")
#let Gini = math.op("Gini")
#let GiniIndex = math.op("GiniIndex")
#let sign = math.op("sign")
#let ReLU = math.op("ReLU")

#info()[
  - ZJU Machine Learning 和西瓜书《机器学习 —— 周志华》的简单笔记
    - 任课老师：赵洲
    - 因为这门课讲得不是很好（高情商），西瓜书本身也写得晦涩难懂，另外机器学习的内容跟当今深度学习的内容有一定 gap，所以只简单记一下*脉络与归纳*，不会记录太复杂的公式推导
]

#counter(heading).update(4)

= 决策树
- 决策树基本流程
  - 略

== 决策树算法的关键：划分选择
- 使用信息熵概念，越小越纯（因此算增益时是用原来更大的减去之后更小的）
  $ Ent(D) = - sum_(k=1)^cY p_k log_2 p_k $
  - 信息增益 (ID3)
    $ Gain(D, a) = Ent(D) - sum_(v=1)^V frac(|D^v|, |D|) Ent(D^v) $
    - $frac(abs(D^v), abs(D))$ 为分支节点权重（样本数越多的分支权重越大）
  - 信息增益率 (C4.5)
    $ GainRatio(D, a) = frac(Gain(D,a), Ent_A (D)) = Gain(D, a) / (- sum_(v=1)^V frac(|D^v|, |D|) log_2 frac(|D^v|, |D|)) $
- 基尼指数：使用基尼值概念，越小越纯
  $
  Gini(D) = sum_(k=1)^cY sum_(k'!=k) p_k p_k' = 1 - sum_(k=1)^cY p_k^2 \
  GiniIndex(D, a) = sum_(v=1)^V frac(|D^v|, |D|) Gini(D^v)
  $
== 克服过拟合的问题：剪枝处理
- 预剪枝（边建树，边剪枝），在验证集上精度提高才划分
  - 降低过拟合风险；显著减少训练时间和测试时间开销
  - 有导致欠拟合的风险（本质是基于贪心禁止某些分支展开）
- 后剪枝（先建树，后剪枝）
  - 保留更多分支，欠拟合风险小；泛化性能往往优于预剪枝
  - 训练时间开销大

== 处理多种类型数据：连续与缺失值
- 决策树只能处理离散属性，因此连续属性需要*离散化*（二分法）
  - 样本集 $D$ 中连续属性 $a$ 出现 $n$ 个不同的取值，以它们的中点作为 $n-1$ 个划分点，挨个考察选出最优
  - 若当前结点划分属性是连续的，该属性还可作为其后代结点的划分属性
  - \*事实上，《统计学习方法》里面介绍 CART 决策树时不仅讲了分类树，也讲了回归树，大致思路是每个节点都用均方误差最小准则将自己对应区域划分为两个子区域，最终得到一个最小二乘回归树。广义的决策树包含分类树与回归树
- 缺失值处理，如果仅使用无缺失样本进行学习，是对数据信息极大的浪费
  - 在属性值缺失的情况下，如何选择划分属性？
    - 跟传统决策树一致，但只在完整样本（子集）中计算信息增益，最终结果乘以 $rho$（$rho$ 表示无缺失样本所占比例）
  - 若划分属性恰好存在某个样本在该属性上缺失值，如何对该样本划分？
    - 为每个样本赋予“权重”概念，正常样本权重为 $1$；而缺失属性样本给每个子节点都划分一份，但样本权值按照子节点概率分配（相当于按比例同时划分到两边去）

== 决策树的变体：多变量决策树
  - 单变量决策树的非叶节点的划分轴是单一属性（分类边界与轴平行）
  - 多变量决策树的非叶节点的划分轴是多个属性的线性组合（或者说，每个非叶节点是 $sum_(i=1)^d w_i x_i = t$ 的线性分类器，分类边界是一个超平面）

= 神经网络
- 也可以参考 #link("https://zhroyn.github.io/MyNotes/%E8%AF%BE%E7%A8%8B/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html")[zhroyn 的笔记]
- 神经网络历史
  - *第一阶段*：1943 年 M-P 模型，1949 年 Hebbian 学习规则，1958 年感知机网络，1960 年自适应线性神经元和最小均方学习算法，1969 年 《Perceptrons》 指出“单层神经网路不能解决非线性问题，多层网络的训练算法尚无希望” —— 神经网络进入低谷
  - *第二阶段*：1982 年 Hopfield 网络，1986 年 BP 算法，1987 年第一届神经网络国际会议(ICNN)。90年代初，伴随统计学习理论和 SVM 的兴起，神经网络由于可解释性弱，试错性强，难以训练，再次进入低谷
  - *第三阶段*：2006 年 Hinton 提出深度信念网络(DBN)，2012 年 AlexNet 在 ImageNet 上大获成功。深度学习进入黄金时代
  - *第四阶段*：我个人认为大模型、多模态时代可以算作深度学习的第四阶段
- 神经元模型
  - 略
- 感知机与多层网络
  - 单层感知机只能解决线性可分问题，多层感知机只需一个包含足够多神经元的隐层便能*以任意精度逼近任意复杂度的连续函数*
- 误差反向传播算法
  - 这里主要需要记一下各个激活函数的公式和导数
  #tbl(
    columns: 3,
    [名称], [公式], [导数],
    [Sigmoid], [$si(x) = frac(1, 1+e^(-x))$], [$si'(x) = si(x)(1 - si(x))$],
    [tanh], [$tanh(x) = frac(e^x - e^(-x), e^x + e^(-x))$], [$tanh'(x) = 1 - tanh^2(x)$],
    [ReLU], [$ReLU(x) = max(0, x)$], [$ReLU'(x) = sign(x)$],
  )
  - 标准、累计 BP 算法，后者在读取整个训练集 $D$ 一遍后才对参数进行更新
    - 但在很多任务中，累积误差下降到一定程度之后，进一步下降会非常缓慢，这时标准 BP 往往会更快获得较好的解，尤其是在训练集非常大时更明显
    - 但一般来说，现在都是用 batch BP 了
  - 另外还需要知道一些常见的损失函数
    #tbl(
      columns: 3,
      [名称], [公式], [常用场景],
      [均方误差(MSE)], [$"MSE" = frac(1, N) sum_(i=1)^N (y_i - hat(y)_i)^2$], [回归问题],
      [交叉熵(CrossEntropy)], [$"CE" = - frac(1, N) sum_(i=1)^N y_i log(hat(y)_i)$], [分类问题],
    )
- 全局最小与局部最小，如何跳出局部最小
  - 随机初始化：多次训练用不同初始参数，陷入不同的局部最小，挑选最优解
  - 模拟退火：每一步都以一定的概率接受比当前解更差的结果，从而有助于“跳出”局部极小。接受“次优解”的概率随着时间的推移而降低，从而保证算法稳定
  - 随机梯度下降：每次迭代只用一个小 batch，因此每次迭代的方向不一定是最优的，但是可以跳出局部最小
  - 遗传算法(GA)
    - 遗传算法会先随机生成一组解，然后通过选择、交叉、变异等操作，逐代优化解的质量，最终得到一个较好的解
    - 这个我自己搜了下，是跟 BP 算法并列的一个东西，模拟自然界对参数进行突变和选择。虽然也可以 GPU 加速，但效率上可能还是差了点，以及它在本身就很玄学的深度学习里又加了一层玄学，可解释性更差了，所以大家都不太用
- 其他常见神经网络
  - 要求不高，但还是了解一下
- 深度学习
- 小结

== 其他常见神经网络
- RBF 网络，因为之前在哪里看到过这玩意儿，多写一点
  - 单隐藏层神经网络（或者说输入隐藏输出三层），每个神经元为一个径向基函数 $rho(bx,bc_i)$，常用的如高斯径向基函数
    $ rho(bx,bc_i)=exp(- beta_i norm(bx-bc_i)^2) \ phi(bx) = sum_(i=1)^q w_i rho(bx,bc_i) $
  - 个人觉得本质上其实跟单层 MLP 没啥区别（限制深度、宽度特化版），只是激活函数变成了径向基函数，把输入映射到高维空间再线性组合得到输出。具有足够多隐层神经元的 RBF 网络能以任意精度逼近任意连续函数
  - 通常用两步法训练参数：1. 用随机采样、聚类等方法确定神经元中心 $bc_i$；2. 用 BP 算法等确定参数 $w_i, beta_i$
  - RBF 说是拟合能力比 BP 神经网络（应该是指同级别的 MLP）强，但从这么多年都没啥人用来看，肯定有它的局限，比如，深度只有一层。当然，不是不能做深，但这又回到梯度消失爆炸的经典问题上了（激活函数导致的）。从这个角度，RBF 说到底也就只是一个特殊点的带参数的激活函数罢了，而从如今越来越趋向于简单一个 ReLU 即可的趋势来看，就更没必要用 RBF 了
- ART 网络
  - ART 网络是竞争学习的一个代表（竞争型学习是一种无监督学习策略，网络的输出神经元相互竞争，只有一个胜者被激活）
  - 网络由比较层、识别层、识别阈值、重置模块构成。其中比较层负责接收输入样本，并将其传递给识别层神经元；识别层每个神经元对应一个模式类，通过计算输入向量与每个模式类代表向量之间的距离来竞争识别输入样本；这个最小的相似度如果大于识别阈值，就归入这一类并更新权重；否则重置模块以它增加一个新的神经元（模式类动态增长）
  - ART 较好的解决了竞争学习中的“可塑性-稳定性窘境”，即神经网络要有学习新知识能力的同时保持对旧知识的记忆；ART 网络可以增量学习或在线学习
- SOM 网络
  - SOM 网络也属于竞争学习
    - 网络中的输出层神经元以矩阵方式排列在二维空间中，拥有各自的权值向量，以此确定对输入向量的获胜神经元
    - 也就是将高维输入映射到低维空间（二维空间坐标），保持了输入数据在高维空间的拓扑结构（高维空间中相似样本点在网络输出后也是邻近的）
- Cascaded 网络
  - 不仅利用训练样本优化连接权值，阈值参数，将网络的结构也当做学习的目标之一（在训练过程中找到适合数据的网络结构）
  - 级联：一开始网络只有输入层和输出层（最小拓扑结构），随着训练进行逐渐加入新的神经元，从而创建起层级结构。当候选神经元加入时，它跟所有隐藏神经元和输入神经元连虚线（原本的网络权重视为实线），并且不跟输出神经元相连
  - 相关：接下来先只训练虚线，相关是指通过最大化候选神经元的输出与网络误差之间的 correlation（换句话说，你可以暂时不降低误差，但你得跟误差非常相关）。这一步训练好后，把候选神经元真正加入网络，把输出边连上，再次训练整个网络
- Elman 网络
  - Elman 网络是最常见的递归神经网络之一，隐藏层神经元的输出被反馈回来，与下一时刻输入层神经元提供的信号一起作为下一时刻隐藏层神经元的输入
- Boltzmann 机
  - Boltzmann 机是一种能量模型网络，其能量函数由神经元的状态（布尔型，只能激活和抑制两种状态）决定，通过最小化能量函数来学习网络参数（达到 Boltzmann 分布）
  - 分为显层（数据的输入输出）和隐层（数据的内在表达）。标准的 Boltzmann 机是全连接的，复杂度很高，难以解决现实任务；通常使用受限 Boltzmann 机(RBM)来简化，仅保留显层和隐层之间的连接，化为二部图
  - 使用对比散度(CD)算法来训练参数（连接权重 $w$ 和影响激活阈值的偏置 $b$）
- 分类：前馈网络、反馈网络和循环、递归网络
  - 前馈网络(Feedforward Network)，是一种最简单的神经网络。各神经元分层排列，每个神经元只与前一层的神经元相连，接收前一层的输出，并输出给下一层，层间没有联系。包括 BP 神经网络、RBF 网络等
  - 至于反馈网络和递归循环网络的分类就乱了起来，毕竟本质上循环、递归也是一种反馈，但是我在网上看到的资料又只说反馈网络是 Hopfield 网络
  - 反馈网络(Feedback Network)，其实就是 Hopfield 网络（也是一种能量模型网络），当给网络一组初始值时，网络通过自行运行而最终收敛到平衡点（网络能量最低点）上
  - 循环网络(Recurrent Network)和递归网络(Recursive Network)，前者包括经典 RNN, LSTM, GRU 等；后者是前者到树形式的推广（递归神经网络父节点仅与一个子节点连接时等价于全连接循环神经网络），最常用的是 Elman 网络
    - 二者的缩写均为 RNN，极易混淆，而事实上后者好像就被前者盖过了（
- 我的一个感觉是，这些所谓“常见神经网络”都设计感太强，不适合做深做大，不适合深度学习参数量当道的理念，因此现在都没什么人用了，权当拓展知识罢

= 支持向量机
== 间隔与支持向量
- 支持向量机的"最大间隔”思想
- 输入 $T={(bx_1,y1), dots, (bx_N,yN)}, bx_i in RR^n, y_i in {-1,+1}$
- 构造并求解约束最优化问题
  $
  &"原始形式" ~~~ max_(bw,b) ga ~~~ s.t. ~ y_i ~ frac(bw dot bx_i + b, norm(bw)) >= ga, ~~ &i=1,2,dots,N \
  &"优化形式" ~~~ max_(bw,b) 1/2 norm(bw)^2 ~~~ s.t. ~ y_i (bw dot bx_i + b) >= 1, ~~ &i=1,2,dots,N
  $
- 输出最大间隔分离超平面、分离决策函数、支持向量
  $
  bw^* dot bx + b^* = 0 \
  f(x) = sign(bw^* dot bx + b^*) \
  H_1, H_2: bw^* dot bx + b^* = 1, bw^* dot bx + b^* = -1
  $

== 对偶问题
- 引入对偶问题，利用其解的稀疏性
- 先构造拉格朗日函数 $L(w,b,al)$，极小极大问题 $min_(w,b) max_al L(w,b,al)$ 转化为极大极小问题 $max_al min_(w,b) L(w,b,al)$
  $
  min_al ~ &1/2 sumiN sumjN al_i al_j y_i y_j (bx_i dot bx_j) - sumiN al_i \
  s.t. ~ &sumiN al_i y_i = 0 \
  &al_i >= 0, i=1,2,dots,N
  $
  - KKT 条件：
    $
    cases(
      al_i >= 0,
      y_i (bw dot bx_i + b) - 1 >= 0,
      al_i (y_i (bw dot bx_i + b) - 1) = 0
    )
    $
    - 主要是第三条，说明支持向量就是那些 $al_i != 0$ 的样本
- 求解得到最优解 $al^*$，进而选择 $al^*$ 的一个正分量 $al_j^*$，计算模型参数
  $ w^* = sumiN al_i^* y_i x_i,\ b^* = y_j - sumiN al_i^* y_i (x_i dot x_j) $
- 求解方法，使用 SMO 算法，执行以下两个步骤直至收敛：
  + 选择一对需要更新的变量 $al_i, al_j$
    - 由于 $sum_i al_i y_i = 0$，实质上只有单自由度
    - SMO 会根据违反 KKT 条件程度选择 $al_i, al_j$
      - 但有点太寄吧难算了，考试时直接画图从结果倒推吧，都初始化为 $0$，然后选最后不应该是 $0$ 的那些个作为 SMO 变量
  + 固定其它变量，通过解析方法求解 $al_i, al_j$ 的最优值，此时对偶问题的约束为
    $ al_i y_i + al_j y_j = - sum_(k!=i,j) al_k y_k, ~~~ al_i, al_j >= 0 $
- 引入对偶问题的原因是，一是对偶问题更容易求解，二是使用内积的形式便于引入核函数（因此，核 SVM 只能用于对偶形式）
  - 但原始 SVM 的计算复杂度在 $O(m)$，而核 SVM 虽然更容易求解，但计算复杂度落在 $O(m^2) wave O(m^3)$ 之间，反而更高了

== 核函数与核方法
- 通过向高维空间映射解决线性不可分的问题
- 常用核函数
  #tbl(
    columns: 4,
    [名称], [公式], [参数], [特点],
    [线性核], [$K(bx_i, bx_j) = bx_i^T bx_j$], [], [计算简单，可解释性强],
    [多项式核], [$K(bx_i, bx_j) = (bx_i^T bx_j + 1)^d$], [$d >= 1$ 为多项式的次数], [涉及到对原始特征的多次转换操作],
    [高斯核\ （RBF 核，径向基函数核）], [$K(bx_i, bx_j) &= exp(- norm(x_i - x_j)^2 / (2 sigma^2))\ &= exp(- ga norm(x_i - x_j)^2)$], [$si > 0$ 为高斯核的带宽], [非线性能力，适合处理复杂数据，\ 但复杂度高容易过拟合],
    [拉普拉斯核], [$K(bx_i, bx_j) = exp(- norm(x_i - x_j) / sigma)$], [$si > 0$], [],
    [Sigmoid 核], [$K(bx_i, bx_j) = tanh(alpha bx_i^T bx_j + beta)$], [$alpha > 0, beta < 0$], [],
  )
- 可以将核方法推广到其他学习模型
  - 比如核 LDA：先将样本映射到高维特征空间，然后在此特征空间中做线性判别分析
- 软间隔与正则化：引入"软间隔"缓解特征空间中线性不可分的问题
  - 对每个样本点引入松弛变量 $xi_i >= 0$
  - 目标函数和约束条件变为
    $
    min_(bw,b,xi) ~ 1/2 norm(bw)^2 + C sumiN xi_i \
    y_i (bw dot bx_i + b) >= 1 - xi_i, ~ i=1,2,dots,N \
    s.t. ~ xi_i >= 0, ~ i=1,2,dots,N
    $
  - 软间隔的对偶形式，基本相同，多一个小于等于惩罚参数 $C$
    $ 0 =< al_i --> 0 =< al_i =< C, ~ i = 1,2,dots,N $
    - KKT 条件
      $
      cases(
        0 =< al_i =< C\, ~~~ xi_i >= 0,
        y_i (bw dot bx_i + b) - 1 + xi_i >= 0,
        (C - al_i) xi_i = 0,
        al_i (y_i (bw dot bx_i + b) - 1 + xi_i) = 0
      )
      $
      - 主要看最后两条，如果 $al_i > 0$ 则为支持向量；进一步如果 $al_i < C$ 则样本恰在最大间隔边界上；否则若 $al_i = C$，根据 $xi_i$ 可以看出该样本在最大间隔内部还是被误分类
  - 软间隔这一块，实际上松弛变量 $xi$ 只是损失函数的一种表达（formally called hinge loss，合页损失函数），写成更一般的形式有
    $ min_f Om(f) + C sumim cal(l)(f(bx_i),y_i) $
    - 前一项为结构风险，后一项为经验风险，而 $C$ 用于对二者进行折衷。放在 SVM 这里，前者描述超平面的间隔大小，后者描述在训练集上的误差
      - $C$ 越大正则化越弱，跟平常神经网络相比有点反直觉。可以这么理解，惩罚越大，就越不允许 $xi_i$，从而倾向于减少训练误差。 Large $C$ $->$ More complex model, Low Bias, High variance
- 支持向量回归
  - 将支持向量的思想应用到回归问题上得到支持向量回归 SVR
  - 允许模型输出和实际输出间存在 $2 ep$ 的偏差
    - 原本是用乘积的形式要求 $f(bx)$ 与 $y$ 都为 $1$ 或都为 $-1$，改成作差的形式后就自然变成了回归问题，并且可以更改损失函数使得不仅仅是完全相等才损失为零
  - 具体而言，引入松弛变量 $xi, hat(xi)$
    $
    min_(bw,b,xi,hat(xi)) 1/2 norm(w)^2 + C sumim (xi_i + hat(xi)_i) \
    s.t. abs(y_i - bw dot bx_i - b) =< ep + xi_i, ~ i=1,2,dots,m \
    xi_i, hat(xi)_i >= 0, ~ i=1,2,dots,m
    $
    - $ep$ 扮演跟 $C$ 相反的角色，$ep$ 越小越倾向于减少训练误差
  - 但我赌他不考，略

= 贝叶斯分类器
== 贝叶斯决策论
- 给定 $N$ 个类别，令 $la_ij$ 代表将属于第 $j$ 类的样本 $bx$ 误分类为第 $i$ 类所产生的损失 ($la_jj = 0$)，则基于后验概率将样本 $bx$ 分到第 $i$ 类的条件风险为
  $ R(ci|bx) = sum_(j=1)^N la_ij P(c_j|bx) $
- 贝叶斯判定准则 (Bayes decision rule):
  $ h^*(bx) = argmin_(c in cY) R(c|bx) $
  - $h^*$ 称为贝叶斯最优分类器 (Bayes optimal classifier)，其总体风险称为贝叶斯风险 (Bayes risk)，反映了学习性能的理论上限
  - 注意：贝叶斯分类器 $!=$ 贝叶斯学习，后者是更广泛的学习概念
- 后验概率 $P(bc|bx)$ 在现实中难以直接获得，机器学习需要根据有限训练样本尽可能准确地估计后验概率，有两种基本策略
  + 判别式 (discriminative): 直接对 $P(bc|bx)$ 建模，代表：决策树、（一般的）BP 神经网络、SVM
    - 这里加个 “一般”，因为现在也有好多基于生成式的神经网络，比如 VAE、GAN
  + 生成式 (generative): 对联合概率密度 $P(bx, bc)$ 建模，然后通过贝叶斯公式计算后验概率，代表：贝叶斯分类器（如朴素贝叶斯）
- 极大似然估计
  - 先假设某种概率分布形式，再基于训练样例对分布的参数进行估计。概率连乘易造成下溢，通常取对数似然函数
  - 结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实分布

== 朴素贝叶斯与半朴素贝叶斯
=== 朴素贝叶斯
- 主要障碍：所有属性上的联合慨率难以从有限训练样本估计获得（组合爆炸、样本稀疏） $->$ 朴素贝叶斯的条件独立性假设
  $
  &P(c|bx) prop P(c) P(bx|c) \
  ==> &P(c|bx) prop P(c) Pi_(i=1)^d P(bx_i|c)
  $
  - 其中 $bx$ 为具有 $d$ 个属性的样本，$x_i$ 为 $bx$ 在第 $i$ 个属性上的取值，$c$ 为类别
  - 估计 $P(c)$
    $ P(c) = frac(abs(D_c), abs(D)) $
  - 估计 $P(bx_i|c)$
    $
    P(bx_i|c) = cases(
      frac(abs(D_(c,bx_i)), abs(D_c))\, &"如果离散",
      frac(1, sqrt(2 pi) si_(c, i)) exp(- frac((x_i - mu_(c, i))^2, 2 si_(c, i)^2))\, ~~ &"如果连续，假定符合高斯概率密度函数"
    )
    $
- 拉普拉斯修正
  $
  P(c) = frac(abs(D_c) + 1, abs(D) + N) \
  P(bx_i|c) = frac(abs(D_(c,bx_i)) + 1, abs(D_c) + N_i)
  $
  - 解决了 “概率连乘导致未出现样本抹除其它属性提供的信息” 的问题
  - 假设了属性值与类别的均匀分布（额外引入的 bias）
- 具体使用时：
  + 若对预测速度要求高 $->$ 预计算所有概率估值，使用时“查表”
  + 若数据更替频繁 $->$ 任数据更替不进行训练，收到预测请求时再估值 (lazy learning)
  + 若数据不断增加 $->$ 基于现有估值，对新样本涉及的慨率估值进行修正 (incremental learning)
- 朴素贝叶斯由于其条件独立性假设，计算联合概率时不需要考虑特征之间的组合，计算复杂度低，适合处理高维、大规模数据；在特征的离散与连续性上，一般对离散特征表现更好

=== 半朴素贝叶斯
- 朴素贝叶斯的“独立性假设”现实中难以成立。半朴素贝叶斯的基本思路：适当考虑一部分属性间的相互依赖信息
- 最常用的是独依赖估计 (One-Dependent Estimator, ODE)，关键在于如何确定每个属性的父属性
$ P(c|bx) prop P(c) Pi_(i=1)^d P(x_i|c, p a_i) $
- 其中 $p a_i$ 为属性 $x_i$ 的父属性，可以看作是在做贝叶斯分类前的超参
- 下面我们有几种确定超参的方法：
  + SPODE (Super-Parent ODE): 假设所有属性都依赖于同一属性，称为“超父”，然后通过交叉验证等方法来确定
  + TAN (Tree Augmented naive Bayes): 以属性间的条件互信息 (conditional mutual information) 为边的权重来构建完全图，再利用最大带权生成树算法，仅保留强相关属性间的依赖性
  + AODE (Averaged One-Dependent Estimator): 尝试将每个属性作为超父构建 SPODE，将有足够训练数据支撑（大于阈值）的 SPODE 集成起来作为最终结果
    $
    P(c|bx) prop sum_(i=1,\ abs(D_x_i) >= m')^d P(c,x_i) Pi_(j=1)^d P(x_j|c, x_i)
    $
    - 其中 $D_x_i$ 是在第 $i$ 个属性上取值为 $x_i$ 的样本集，$m'$ 为阈值常数
    $ hat(P)(c,x_i) = frac(abs(D_(c,x_i))+1,abs(D)+N_i), ~~~ hat(P) (x_j|c,x_i) = frac(abs(D_(c,x_i,x_j))+1,abs(D_(c,x_i))+N_j) $
    - 其中 $D_(c,x_i,x_j)$ 是类别为 $c$ 且第 $i$ 个属性取值为 $x_i$ 且第 $j$ 个属性取值为 $x_j$ 的样本集，$N_i$ 为第 $i$ 个属性可能取值的个数

=== 贝叶斯网
- 进一步考虑属性间的高阶依赖，最简单的做法是 ODE $->$ KDE，但计算复杂度指数级增加，考虑高阶依赖需要其它办法
- 贝叶斯网 (Bayesian Network)，亦称信念网 (Brief Network)，是一种有向无环图 (DAG)，图中每个节点代表一个属性，节点之间的有向边代表属性间的依赖关系
- 给定父结点集，贝叶斯网假设每个属性与其*父节点的非后裔属性*独立
  #fig("/public/assets/Courses/ML/2024-10-31-20-46-11.png", width: 60%)
  - 以上图为例：
    + 学生的 Grade 取决于课程的 Difficulty 和学生的 Intelligence；而 Grade 又决定了学生能否从教授那里得到一份好的 Letter；
    + 学生的 Intelligence 除了会影响他们的 Grade，还会影响他们的 SAT 分数；
    + Intelligence 会影响 SAT 分数，但 SAT 不会影响 Intelligence（箭头的方向表示了因果关系）；
    + 在同等 Intelligence 下，SAT 跟 Grade 无关；
    + 若已知学生的 Grade，那么 Difficulty 和 Intelligence 并不独立（试想，如果课程难度很高，为了达到这个 Grade，你必须得很聪明）；但如果 Grade 未知，那么 Difficulty 和 Intelligence 是独立的
- 贝叶斯网络中三变量典型依赖关系
  #fig("/public/assets/Courses/ML/2024-10-31-21-07-31.png", width: 60%)
- 利用“道德图”分析条件独立性
  - 将贝叶斯网络转化为无向图，特别地对于 V 型结构把父节点相连
  - 若 $x$ 和 $y$ 能被 $bz$ 分成两个联通分支，则 $x$ 和 $y$ 在给定 $bz$ 的条件下独立，即 $x perp y | bz$
- \*在概率图模型中，有向图模型 $->$ 马尔可夫链和贝叶斯网，无向图模型 $->$ 马尔可夫网
  - 马尔可夫链跟贝叶斯网络非常像，前者是后者的特例，后者是前者的推广（链与图的关系）
  - 如果把概率图模型做一个梳理，便如下有一个*依次递进*的关系：
    + 首先，将随机变量作为结点，若两个随机变量相关或者不独立，则将二者连接一条边；若给定若干随机变量，则形成一个*有向图*，即构成一个网络
    + 如果该网络是*有向无环图*，则这个网络称为*贝叶斯网络*
    + 如果这个图退化成*线性链*的方式，则得到*马尔可夫模型*。因为每个结点都是随机变量，其看成各个时刻（或空间）的相关变化，以随机过程的视角，则可以看成是*马尔可夫过程*
    + 若上述网络是无向的，则是*无向图模型*，又称*马尔可夫随机场*或者*马尔可夫网络*
    + 如果在给定某些条件的前提下，研究这个马尔可夫随机场，则得到*条件随机场*
    + 如果使用条件随机场解决标注问题，并且进一步将条件随机场中的网络拓扑变成线性的， 则得到*线性链条件随机场*
- 贝叶斯网络的训练（学习）
  - 评分函数 (score function) 评估贝叶斯网与训练数据的契合程度
  - 评分函数的第一项是计算编码贝叶斯网 $B$ 所需的字节数，第二项是计算 $B$ 所对应的概率分布 $P_B$ 需要多少字节来描述 $D$（对数似然，对一个训练数据上的概率分布，用哈夫曼编码之类使经常出现的样本有更短编码，从而建立概率分布到编码长度的映射）
  #fig("/public/assets/Courses/ML/2024-10-31-21-30-46.png", width: 60%)
  - 搜索最优贝叶斯网络结构是 NP 难问题，一般采用贪心算法或限制网络为树形结构等方法来降低求解难度
- 贝叶斯网络的推断
  - 查询 (query) 贝叶斯网络，基于已知属性变量的观测值（或称证据，evidence），来推断 (inference) 其他属性变量的取值
  - 不幸的是，即使网络已经建好，精确推断也是 NP 难问题。为了在有限时间内求得近似解，常常降低精度要求，采用近似推断方法，如*吉布斯采样*、*变分推断*等
  - 吉布斯采样：待查询变量 $bold(Q)={Q_1,Q_2,...,Q_n}$，证据变量 $bold(E)={E_1,E_2,...,E_k}$，查询的目标值 $bold(q)={q_1,q_2,...,q_n}$，证据变量取值 $bold(e)={e_1,e_2,...,e_k}$，求解后验概率 $P(bold(Q)=bold(q)|bold(E)=bold(e))$
    + 先随机对 $bold(Q)$ 赋初值（其它变量与证据 $bold(E)=bold(e)$ 一致）
    + 逐个考察每个非证据变量（查询目标） $Q_i$：假定所有其他属性取当前值，从网络推断出采样概率，然后根据该概率采样
      - 即在贝叶斯网所有变量的联合状态空间与证据取值一致的子空间中 *“随机游走”*，每一步仅依赖上一步状态，属于马尔可夫链，最后一般会收敛到平稳分布
      - $arrow.t$ 这样解释不就简单多了#strike[，挠贪西瓜书会不会解释概念啊]
    + 执行 $T$ 次上述步骤，有 $n_q$ 次取到 $bold(q)$，则 $P(bold(Q)=bold(q)|bold(E)=bold(e)) approx n_q/T$
    #fig("/public/assets/Courses/ML/2024-12-29-11-53-19.png", width: 60%)
  - 变分推断，涉及 EM 算法和 KL 散度，看不懂且书上这一块没有，略
