#import "/src/components/TypstTemplate/lib.typ": *

#show: project.with(
  title: "机器学习",
  lang: "zh",
)

#let nh = math.text("nh")
#let nm = math.text("nm")
#let dist = math.text("dist")
#let LGG = math.text("LGG")

#info()[
  - ZJU Machine Learning 和西瓜书《机器学习 —— 周志华》的简单笔记
    - 任课老师：赵洲
    - 因为这门课讲得不是很好（高情商），西瓜书本身也写得晦涩难懂，另外机器学习的内容跟当今深度学习的内容有一定 gap，所以只简单记一下*脉络与归纳*，不会记录太复杂的公式推导
]

#counter(heading).update(12)

= 特征选择与稀疏学习
== 子集搜索与评价
- 特征的分类
  - 相关特征：对当前学习任务有用的属性
  - 无关特征：与当前学习任务无关的属性
  - 冗余特征：暂不涉及
- 特征选择
  - 从给定的特征集合中选出任务相关特征子集，必须确保不丢失重要特征
  - 可以减轻维数灾难，降低学习难度
  - 遍历所有子集，组合爆炸；可行方法为：产生初始候选子集 $->$ 评价候选子集的好坏 $->$ 基于评价结果产生下一个候选子集
- 子集搜索
  - 用贪心策略选择包含重要信息的特征子集
  + 前向搜索：逐渐增加相关特征（最优子集初始为空集，特征集合初始时包括所有给定特征，每次从特征集合中选择一个移入最优子集，直到出现性能下降的情况）
  + 后向搜索：从完整的特征集合开始，逐渐减少特征
  + 双向搜索：每一轮逐渐增加相关特征，同时减少无关特征
- 子集评价
  - 特征子集确定了对数据集的一个划分，每个划分区域对应着特征子集的某种取值；样本标记对应着对数据集的真实划分
  - 用样本标记的真实划分和特征自己 $A$ 的划分计算信息熵，从而得到信息增益

== 特征选择
- 将特征子集搜索机制与子集评价机制相结合，即可得到特征选择方法。常见的有三类：过滤式、包裹式、嵌入式
- 过滤式
  - 先用特征选择过程过滤原始数据，再用过滤后的特征来训练模型；特征选择过程与后续学习器无关
  - Relief (Relevant Features) 方法
    - 为每个初始特征赋予一个“相关统计量”，度量特征的重要性。然后可以用一个阈值过滤掉相关统计量低的特征，也可以指定个数然后选择相关统计量高的特征
    - 核心在于如何确定相关统计量，使用猜中近邻 (near-hit) 和猜错近邻 (near-miss)，分别在 $x_i$ 的同类和异类样本中寻找最近邻
    - 相关统计量在属性 $j$ 的分量为
      $ de^j = sumiN - "diff"(x_i^j, x_(i,nh)^j)^2 + "diff"(x_i^j, x_(i,nm)^j)^2 $
      - 若 $j$ 为离散属性，则当 $x_i^j = x_(i,nh)^j$ 时 $"diff" = 0$，否则为 $1$
      - 若 $j$ 为连续属性，则 $"diff" = abs(x_i^j - x_(i,nh)^j)$，注意需要把 $x_i^j, x_(i,nh)^j$ 规范化到 $[0, 1]$ 区间
      - 如果在属性 $j$ 上，$x_i$ 与 $x_(i,nh)$ 的距离比与 $x_(i,nm)$ 的距离小，则 $de^j$ 为正，说明该属性对区分样本正异有用
    - relief 只需在数据集的采样上运行，其时间开销随采样次数和原始特征数目线性增长，运行效率很高
    - relief 的多分类变体 relief-F
      - 猜中近邻：第 $k$ 类中 $x_i$ 的最近邻 $x_(i,nh)$
      - 猜错近邻：第 $k$ 类以外的最近邻 $x_(i,l,nm) (l = 1,2,dots,"类别数";l!=k)$
      - 相关统计量在属性 $j$ 的分量为（$p_l$ 为第 $l$ 类的概率或者说数据集中的占比）
        $ de^j = sumiN - "diff"(x_i^j, x_(i,nh)^j)^2 + sum_(l!=k) p_l times "diff"(x_i^j, x_(i,l,nm)^j)^2 $
- 包裹式
  - 直接把最终将要使用的学习器的性能作为特征子集的评价准则（为给定学习器选择最“量身定做”的特征子集，性能通常更好了；但因为多次训练学习器，计算开销更大）
  - LVW (Las Vegas Wrapper)
    + 在循环的每一轮*随机产生*一个特征子集（好尼玛粗暴，$2^abs(A)$ 个组合。。。）
    + 在随机产生的特征子集上通过交叉验证推断当前特征子集的误差
    + 进行多次循环，选择误差最小的特征子集（或者误差相当但特征数目更少的特征子集）作为最终解
- 嵌入式
  - 将特征选择过程与学习器训练过程融为一体，在同一个优化过程中完成（训练过程中自动进行特征选择），常见例子就是正则化
  - L2 正则化，也叫 “岭回归”(Ridge Regression)
  - L1 正则化，也叫 “Lasso”，可以产生稀疏解。求解有一个叫 PGD 的方法，不看了
== 稀疏表示与字典学习
- 稀疏表示：矩阵中有很多零元素，且非整行整列出现。优势在于计算和存储更有效率
- 字典学习：为普通稠密表达的样本找到合适的字典，将样本转化为稀疏表示的过程
  - 给定数据集 ${bx_1, bx_2, dots, bx_N}, bx_i in RR^(N times k)$，学习目标是字典矩阵 $bB in RR^(d times k)$ 和稀疏表示 $al_i in RR^k$，其中 $k$ 为字典词汇量（用户指定）
    $ min_(bB,al_i) sumiN norm(bx_i - bB al_i)_2^2 + la sumiN norm(al_i)_1 $
  - 求解，两步迭代优化
    + 固定 $bB$ 然后利用 LASSO 求解
      $ min_(al_i) sumiN norm(bx_i - bB al_i)_2^2 + la sumiN norm(al_i)_1 $
    + 固定 $al_i$，记作 $bA$，更新 $bB$。这里方法很多，西瓜书讲了 K-SVD 算法，不看了
      $ min_(bB) sumiN norm(bX - bB bA)_2^2 $

== 压缩感知
- 目的：利用部分数据（压缩、丢包后的数字信号）恢复全部数据
- 长度为 $m$ 的离散信号，采样后得到长度为 $n$ 的信号 $y$，$n << m$，该过程表示为 $y = Phi x$，一般情况下无法还原
- 但如果存在某个线性变换 $Psi in RR^(m times m)$，使得 $x=Psi s$ 而 $s$ 是稀疏向量，即
  $ y = Phi Psi s eq.delta A s $
  - 此时，如果 $A in RR^(n times m)$ 具有 “限定等距性”(Restricted Isometry Property)，可以近乎完美地恢复 $s$
    - k-RIP：存在常数 $de_k in (0,1)$，使得对任意向量 $s$ 和 $A$ 列方向的子矩阵 $A_k in RR^(n times k)$，有
      $ (1-de_k)norm(s)_2^2 =< norm(A_k s)_2^2 =< (1+de_k) norm(s)_2^2 $
  - 如果 $A$ 满足 k-RIP，就可以用优化问题恢复 $s$，进而恢复出 $x$
    $ min_s norm(s)_0 \ s.t. ~ y = A s $
  - L0 范数极小化为 NP-H 问题，转化为共解的 L1 范数问题
    $ min_s norm(s)_1 \ s.t. ~ y = A s $
  - 可以进一步转化为 LASSO 的等价形式再通过 PGD 求解，即使用"基寻踪去噪" (Basis Pursuit De-Noising)
- 压缩感知应用：矩阵补全
  - $X$ 为待求稀疏信号，$A$ 表示已观测信号，$Om$ 表示 $A$ 中已观测位置的下标集合。要在不提升秩的情况下补全矩阵
    $ min_X "rank"(X) \ s.t. (X)_ij = (A)_ij, ~ (i, j) in Om $
  - 上式为 NP-H 问题，可以通过最小化*矩阵核范数*来近似求解
    $ min_X norm(X)_* \ s.t. (X)_ij = (A)_ij, ~ (i, j) in Om $
    - 矩阵核范数：$rank(X)$ 在集合 ${X in RR^(m times n): norm(X)_F^2 =< 1}$ 上的凸包，它等于矩阵的奇异值之和
      $ norm(X)_* = sum_(j=1)^(min{m,n}) si_j (X) $
  - 上式可通过半正定规划 (SDP) 求解。研究表明，若 $A$ 的秩为 $r$，$n MM m$，则只需观察到 $O(m r log^2 m)$ 个元素就能完美恢复出 $A$

= 计算学习理论
- [ ] TODO（不考）


= 半监督学习
== 未标记样本
- 主动学习：主动选择未标记样本进行标记，但尽量减少查询（外界交互）次数
- 半监督学习：让学习器完全不依赖外界交互、自动地利用未标记样本来提升学习性能。一般需要对样本作一定假设
  + 聚类假设：假设数据存在簇结构，同一个簇的样本属于同一个类别
  + 流形假设：假设数据分布在一个流形结构上，邻近的样本拥有相似的输出值
- 半监督学习可以进一步分为
  + 纯半监督学习：基于“开放世界”假设，假定未标记样本并非最终要预测的数据
  + 直推学习：基于“封闭世界”假设，假定未标记样本就是最终要预测的数据，学习目的就是在其上获得最优泛化性能

== 生成式方法
- 假设所有数据都是同一个潜在模型生成的（先验），进而通过 EM 算法进行极大似然估计
- 高斯混合模型在半监督学习中的应用
  - 跟之前差不多，只是要注意后验概率 $ga_jk$ 只对未标记样本计算，对已标记样本已知 $1$ 和 $0$
- 此类算法的区别主要在生成模型的假设，且这个假设决定了模型的性能

== 半监督 SVM
- 在考虑未标记样本后
  - S3VM：试图找到能将两类有标记样本分开，且穿过数据低密度区域的划分超平面
  - TSVM
    - 尝试将每个未标记样本分别作为正例或反例，然后在所有这些结果中，寻求一个在所有样本上间隔最大化的划分超平面 $->$ 穷举过于低效
      $
      min_(bw, b, hat(by), bxi) &1/2 norm(bw)_2^2 + C_l sum_(i=1)^l xi_i + C_u sum_(i=l+1)^N xi_i \
      s.t. ~ &y_i (bw^T bx_i + b) >= 1 - xi, i = 1, dots, l, \
      &hat(y)_i (bw^T bx_i + b) >= 1 - xi_i i = l + 1, dots, N, \
      &xi_i >= 0, i = 1, dots, N
      $
    - 局部搜索迭代求近似解
      #algo(title: [*Algorithm*: TSVM])[
        + 首先用有标记样本基于上式训练一个 SVM
        + 用这个 SVM 在未标记样本上跑出一系列很可能错误的伪标记（此时需要松弛变量系数 $C_u << C_l$）
        + 对每一对标记指派为异类且很可能错误的伪标记样本，交换它们的标记，然后重新基于上式训练 SVM
        + 循环上述过程并逐渐增大 $C_u$
      ]
    - 在对未标记样本进行标记指派及调整的过程中，有可能出现*类别不平衡问题*，对 SVM 的训练造成困扰
      - 可对算法稍加改进：将优化目标中的 $C_u$ 项拆分为 $C_u^+, C_u^-$

== 图半监督学习
- 利用图的方法做半监督学习
  - 将数据集映射为一个图，每个样本对应一个节点，节点之间的边表示样本之间的相似性
  - 可以将有标记样本对应节点想象为染过色，颜色在图上扩散，最终染满整个图，这就是图半监督学习的基本过程
  - 形式化定义
    - 一个图对应一个矩阵，叫做亲和矩阵 $W$
    - 我们要学习的是一个实值函数 $f: V -> RR$，具有分类规则 $y_i = sign(f(bx_i))$
    - 结合起来定义能量函数，作为最小化目标
      $ E(f) &= 1/2 sumim sumjm (W)_ij (f(bx_i)-f(bx_j))^2 \ &= bf^T (D-W) bf eq.delta bf^T De bf $
    - 最后会化为拉普拉斯矩阵的形式，然后用分块矩阵等推导，不细看了

== 基于分歧的方法
- 现实中，一个数据对象可能同时拥有多个"属性集" (attribute set) ，每个属性集就构成了一个“视图”(view)
- 两个假设，后者很难满足（但即使如此，基于分歧的方法仍然能有效提升弱分类器性能）
  - 相容性：不同视图所包含的关于输出空间的信息是一致的。
  - 相容互补性：假设数据拥有两个充分（每个视图都包含足以产生最优学习器的信息）且条件独立（在给定类别标记条件下两个视图独立）视图
- 协同训练算法
  #algo(title: [*Algorithm*: 协同训练])[
    + 首先，在每个视图上基于有标记样本分别训练出一个*分类器*
    + 然后，让每个分类器分别去挑选自己 “*最有把握的*” 未标记样本赋予伪标记，并将*伪标记样本*提供给另一个分类器作为新增的有标记样本用于训练更新……
    + 这个"*互相学习、共同进步*"的过程不断迭代进行，直到两个分类器都不再发生变化，或达到预先设定的迭代轮数为止
  ]

== 半监督聚类
- 聚类是一种典型的无监督学习任务，但现实中往往能获取一些额外监督信息
- 第一种监督信息，在度量学习一节中提到“必连”和“勿连”约束，由此导出*约束 k 均值算法*
  - 跑起来跟普通 k 均值算法似乎一毛一样，只是过程中会检测约束条件。如果不满足就直接返回错误提示
- 第二种监督信息，是“类别先验”信息，即已知某些样本属于某个类别（有标记样本），由此导出*约束种子 k 均值算法*
  - 只是将这些种子用作初始化 k 均值的聚类中心，并且在聚类迭代过程中不改变种子的簇隶属关系

= 概率图模型
- 概率模型：提供了一种*描述框架*，将学习任务归结于计算变量的概率分布
- 推断：在概率模型中，利用已知变量推测*未知变量的分布*
  - 记所关心的变量集合为 $Y$，可观测变量集合为 $O$，其他变量的集合为 $R$
  - 生成式: $P(Y,R,O)$，判别式: $P(Y,R|O)$，推断：由 $P(Y,R,O)$ 或 $P(Y,R|O)$ 推测 $P(Y|O)$
- 概率图模型：用图表示变量相关关系。最常见的是“变量关系图”，用一个节点表示一个或一组随机变量，边表示概率相关关系
  - 使用*有向无环图*表示依赖关系，称为*有向图模型*或*贝叶斯网*
  - 使用*无向图*表示相关关系，称为*无向图模型*或*马尔可夫网*

== 隐马尔可夫模型
- 状态变量：假定状态变量是隐藏的、不可被观测的，因此状态变量亦称隐变量。一共有 $n$ 个状态和 $N$ 种取值
- 观测变量：可以是离散型也可以是连续型。一共有 $n$ 个观测和 $M$ 种观测值
- 隐马尔可夫模型中最经典的是马尔可夫链：现在决定未来，不受过去影响
- 确定一个隐马尔可夫模型需以下三组参数
  - 状态转移概率：在各个状态间转换的概率 $A in RR^(N times N)$
  - 输出现测概率：根据当前状态获得各个观测值的概率 $B in RR^(N times M)$
  - 初始状态概率 $bpi = (pi_1, pi_2, dots, pi_N)$
- 产生观测序列 —— 根据 $bpi$ 游走
  #algo(title: [*Algorithm*: 隐马尔可夫观测序列])[
    + 设置 $t=1$,并根据初始状态概率 $bpi$ 选择初始状态 $y_1$;
    + 根据状态 $y_t$ 和输出观测概率 $B$ 选择观测变量取值 $x_t$；
    + 根据状态 $y_t$ 和状态转移矩阵 $A$ 转移模型状态，即确定 $y_(t+1)$；
    + 若 $t < n$，设置 $t=t+1$，并转到第 2 步，否则停止
  ]
- 隐马尔可夫模型的三个基本问题
  + 给定模型 $la=[A,B,pi]$，如何有效计算其产生观测序列 $x={x_1,x_2,dots,x_n}$ 的概率 $P(x|la)$？换言之，如何评估模型与观测序列之间的匹配程度？
  + 给定模型 $la=[A,B,pi]$和观测序列 $x={x_1,x_2,dots,x_n}$，如何找到与此观测序列最匹配的状态序列 $y={y_1,y_2,dots,y_n}$？换言之，如何根据观测序列推断出隐藏的模型状态？
  + 给定观测序列 $x={x_1,x_2,dots,x_n}$，如何调整模型参数 $la=[A,B,pi]$ 使得该序列出现的概率 $P(x|la)$ 最大？换言之，如何训练模型使其能最好地描述观测数据？

== 马尔可夫随机场
- 马尔可夫随机场 (Markov Random Field, MRF) 是马尔可夫网的一种，是*无向图模型*
- 马尔可夫随机场有一组势函数（亦称“因子”），是定义在变量子集上的非负实函数，主要用于定义概率分布函数
  - 势函数常用指数函数定义以满足非负性
    $ psi_(A B) (x_A, x_B) = cases("high"\, ~~~~ &"if" x_A =x_C, "low"\, &"otherwise") --> x_A, x_B "偏好取值相同" $
- 图论：团（任意两节点间都有边连接）和极大团，即强连通分量
- 马尔可夫随机场中，多个变量的联合概率分布能基于团分解为多个因子乘积，每个因子仅与一个团相关，并且可进一步用极大团分解
  $ P(x) = 1/Z Pi_(Q in C) psi_Q (x_Q) = 1/Z^* Pi_(Q in C^*) psi_Q (x_Q) $
- 马尔可夫随机场的条件独立性
  - 全局马尔可夫性：给定两个变量子集 $x_A, x_B$ 的分离集 $x_C$，则这两个变量子集在分离集下条件独立 $x_A perp x_B | x_C$
    - 分离集：若从节点集 $A$ 中的节点到 $B$ 中的节点都必须经过节点集 $C$ 中的节点，则称 $A$ 和 $B$ 被 $C$ 分离
  - 局部马尔可夫性：给定某变量的邻接变量，则该变量条件独立于其他变量（出去的路都被堵住咯）
  - 成对马尔可夫性：给定所有其他变量，两个非邻接变量条件独立（你俩不抱团，被孤立辣）

== 条件随机场
- 条件随机场 (Conditional Random Field,CRF) 是一种判别式无向图模型，试图对多个变量在给定观测值后的条件概率进行建模
  - 与马尔可夫随机场没有显著区别，只不过一个处理联合概率，一个处理条件概率
- 类似马尔可夫链，若图 $G$ 的每个变量 $y_v$ 都满足马尔可夫性（只取决于邻接节点，即满足下式），则 $y,x$ 构成一个条件随机场
  $ P(y_v|x,y_(V\\{v})) = P(y_v|x,y_(n(v))) $
- 条件随机场中，通过选用指数势函数并引入特征函数，来定义条件概率
  - 转移特征函数
  - 状态特征函数
  - 特征函数通常是实值函数，以刻画数据的一些很可能成立或期望成立的经验特性

== 学习与推断
- 基于概率图模型，我们能对目标变量的边际分布 (marginal distribution) 或以某些可观测变量为条件的条件分布进行推断
  - *推断*的目标为边际概率 $P(x_F)$、条件概率 $P(x_F | x_E)$，条件概率可以转化为联合概率（基于概率图模型获得）和边际概率，因此重点就在于高效地计算边际概率
- 对概率图模型，还需确定具体分布的参数，这称为参数估计或参数*学习*问题
  - 通常使用极大似然估计或最大后验概率估计求解
  - 但若将参数视为待推测的变量，则参数估计过程和*推断*十分相似，可以“吸收”到推断问题中
- 推断方法
  - 精确推断：精确计算边际概率，但计算复杂度随极大团规模指数增长，实质是动态规划
    - *变量消去法*：通过利用乘法对加法的分配律，变量消去法把多个变量的积的求和问题，转化为对部分变量交替进行求积与求和的问题，从而把运算限制在局部
      #fig("/public/assets/Courses/ML/2025-01-01-11-42-44.png", width: 50%)
    - *信念传播法*
      - 信念传播算法将变量消去法中的求和操作看作一个消息传递过程，较好地解决了求解多个边际分布时的重复计算问题
      - 在信念传播算法中，一个结点仅在接收到来自其他所有结点的消息后才能向另一个结点发送消息，且结点的边际分布正比于它所接收的消息的乘积
      - 若图结构中没有环，则信念传播算法经过两个步骤即可完成所有消息传递，进而能计算所有变量上的边际分布：
        + 指定一个根结点，从所有叶结点开始向根结点传递消息，直到根结点收到所有邻接结点的消息
        + 从根结点开始向叶结点传递消息，直到所有叶结点均收到消息
        #fig("/public/assets/Courses/ML/2025-01-01-11-47-57.png", width: 50%)
  - 近似推断：近似计算边际概率，更常用

== 近似推断
- 近似推断方法大致可分为两大类：
  + 第一类是采样(sampling) ，通过使用随机化方法完成近似
  + 第二类是使用确定性近似完成近似推断，典型代表为变分推断(variational inference)
- 采样方法中，以马尔可夫链蒙特卡洛(MCMC)方法最为常用
  - 基本思想就是构建一个马尔可夫链，使其平稳分布为目标分布，然后在该马尔可夫链上进行随机游走，最后样本将趋于平稳分布也就是目标分布。因此马尔可夫链转移概率的构造至关重要
  - MCMC 方法中，Metropolis-Hastings 为其重要代表
    #algo(title: [*Algorithm*: MH 算法])[
      + 从一个初始状态 $x^(0)$ 开始
      + 从一个提议分布 $q(x^*(t+1)*|x^(t))$ 中采样一个候选状态 $x^*$
      + 从一个均匀分布 $U(0,1)$ 中采样一个随机阈值 $u$
      + 计算接受概率 $alpha = min{1, frac(P(x^*)q(x^(t)|x^*), P(x^(t))q(x^*|x^(t)))}$
      + 若 $alpha =< u$ 接受候选状态 $x^(t+1)=x^*$，否则保持当前状态 $x^(t+1) = x^(t)$
      + 重复 2-5 步直到收敛
    ]
  - 吉布斯抽样法也是 MCMC 法的一种，被视为 MH 算法的特例
    #algo(title: [*Algorithm*: Gibbs Sampling])[
      + 随机或以某个次序选取某变量 $x_i$
      + 根据 $x$ 中除 $x_i$ 外变量的现有取值，计算条件概率 $p(x_i|x_(oi))$，其中 $x_(oi)={x_1, dots, x_(i-1), x_(i+1), dots, x_N}$
      + 根据 $p(x_i|x_(oi))$ 对变量 $x_i$ 采样，用采样值代替原值
    ]
- 变分推断
  - 盘式记法
  - 通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近似分布的类型，从而得到一种局部最优、但具有确定解的近似后验分布
  - 借助变分推断，将复杂的多变量 $z$ 拆解为一系列相互独立的多变量 $z_i$，并可假设这些变量服从某种简单分布，从而简化推断问题
  - 在实践中使用变分法时，最重要的是考虑如何对隐变量进行拆解，以及假设各变量子集服从何种分布，在此基础上套用最优分布的式子再结合 EM 算法即可进行概率图模型的推断和参数估计
  - 显然，若隐变量的拆解或变量子集的分布假设不当，将会导致变分法效率低、效果差

== 话题模型
- 话题模型(topic model)是一族生成式有向图模型，主要用于处理离散型的数据(如文本集合)，在信息检索、NLP 等领域有广泛应用
  - 隐狄利克雷分配模型 (Latent Dirichlet Allocation，简称LDA) 是话题模型的典型代表
- 概念：词(word)、文档(document)、话题(topic)
  - 词：待处理数据的基本离散单元，例如在文本处理任务中，一个词就是一个英文单词或有独立意义的中文词
  - 文档：待处理的数据对象，它由一组词组成（不计顺序），例如一篇论文、一个网页都可看作一个文档
    - 这样的表示方式称为"词袋" (bag-of-words)。数据对象只要能用词袋描述，就可使用话题模型
  - 话题：表示一个概念，即一系列相关的词以及在该概念下出现的概率
- LDA 从生成式模型的角度看待文档和话题
  - 每篇文档 $t$ 包含多个话题，话题分布的分布满足参数为 $al$ 的狄利克雷分布
  - 随机采样这一分布得到文档 $t$ 的话题分布 $Th_t$
  - 根据 $Th_t$ 进行话题指派，得到文档 $t$ 中第 $n$ 个词的话题 $Z_(t,n)$
  - 根据指派的话题 $Z_(t,n)$ 从对应词频分布 $be_k$ 随机采样生成最后的词
- LDA 的模型参数课通过极大似然法估计，但一般难以直接求解，常采用吉布斯抽样或变分法进行近似推断

= 规则学习
== 基本概念
- 机器学习里的规则：“若……，则……”
  - 回归
    $ "若" hat(h)(x)=hat(y), ~"则"~ y=hat(y) $
  - 分类
    $ "若" h(x)>0, ~"则"~ "class"=1, "否则" "class"=-1 $
  - 聚类
    $ "若" forall j != i, dist(x, c_i) =< dist(x,c_j), ~"则"~ x in c_i $
- 逻辑规则、规则集
  - 发生冲突时，冲突消解：顺序规则、缺省规则、元规则
- 命题逻辑 $->$ 命题规则
- 一阶逻辑 $->$ 一阶规则
- 具体概念类似校内课程《人工智能逻辑》，应该还有一点印象，不赘述

== 序贯覆盖
- 序贯覆盖的做法是逐条归纳
  - 在训练集上每学到一条规则，就将该规则覆盖的样例去除，然后以剩下的样例组成训练集重复上述过程（分治策略）
- 关键是如何从训练集学出单条规则（单条规则学习）
  - 目标：寻找一组最优的逻辑文字来构成规则体
  - 本质：搜索问题
    - 搜索空间大，易造成组合爆炸
  - 方法：
    - 自顶向下：一般到特殊（泛化），从一般规则开始逐渐添加新文字直到满足预定条件，亦称为“生成-测试”法
    - 自底向上：特殊到一般（特化），从特殊规则开始逐渐删除文字，亦称为“数据驱动”法
    - 前者泛化性好、鲁棒性强，通常用于命题规则学习；后者更适合训练样本较少的情形，对一阶规则这类假设空间复杂的任务较多
  - 规则评判：增加/删除哪一个候选文字
    - 准确率、信息熵增益（率）、基尼系数……
  - 规避局部最优
    - 集束搜索（beam search）：每次保留最优的多个候选规则
- 由于序贯覆盖法简单有效，几乎所有规则学习算法都以它为基本框架
- 它能方便地推广到多分类问题上，只需将每类分别处理即可
  - 当学习关于第 $c$ 类的规则时，将所有属于类别 $c$ 的样本作为正例，其余作为反例


== 剪枝优化
- 规则生成本质上是一个贪心搜索过程，需有一定的机制来缓解过拟合的风险，最常见的做法是剪枝(pruning)
- 与决策树相似，有
  - 预剪枝
    - 似然率统计量
  - 后剪枝
    - 减错剪枝(REP)
      - 分为训练集和验证集，用验证集反复剪枝直到准确率无法提高
      - 穷举所有可能的剪枝操作（删除文字，删除规则），复杂度非常高
  - 二者结合
    - IREP
      - 每生成一条新规则即对其进行REP剪枝
      - IREP\* 改进了规则性能度量指标，在剪枝时删除规则尾部的多个文字，并在最终得到规则集之后再进行一次 IREP 剪枝
    - RIPPER
      - RIPPER 先使用 IREP\* 剪枝机制生成规则集 $R$，再用后处理机制将所有规则放在一起优化，通过全局的考虑来缓解序贯覆盖贪心算法的局部性
     #algo(title: [*Algorithm*: RIPPER])[
      + 生成规则集
      + 选取一条规则，找到其覆盖的样例
        + a) 重新生成规则（替换规则和修订规则）
        + b) 特化原规则再泛化
      + 把原规则和新规则分别置入规则集进行评价，留下最好的
      + 反复优化直到无法进步
     ]


== 一阶规则学习
- 命题逻辑表达能力低，命题规则学习难以处理对象之间的关系
- 这需要以比较的形式，用一阶逻辑表示，用一阶规则学习。数据也需要转化为关系型数据
- FOIL
  - 序贯覆盖生成规则集，自顶向下学习单条规则
  - 候选文字需考虑所有可能的选项，新加入的文字应包含至少一个已出现的变量
  - 使用 FOIL 增益来选择文字
    $ F_"Gain" = hm_+ times (log frac(hm_+, hm_+ + hm_-) - log frac(m_+, m_+ + m_-)) $
    - 与决策树使用的信息增益不同，仅考虑正例的信息量，使用新规则覆盖的正例数作为权重
      - 这是因为关系型数据中正例往往远少于反例数，因此通常对他们赋予更多的关注（以至于都不看反例。。。）
  - 每次按照 FOIL 增益选择最大的候选文字，直到无法覆盖反例为止。最终生成的单条规则加入规则集，此后 FOIL 使用后剪枝优化
  - 若允许将目标谓词作为候选文字加入规则体，则 FOIL 能学出*递归规则*；若允许将*否定形式的文字* $not f$ 作为候选，则往往能得到更简洁的规则集
- FOIL 可大致看作命题规则学习与归纳逻辑程序设计之间的过渡
  - 其自顶向下的规则生成过程不能支持*函数*和*逻辑表达式嵌套*，因此规则表达能力仍有不足；
  - 但它是把命题规则学习过程通过变量替换等操作直接转化为一阶规则学习，因此比一般归纳逻辑程序设计技术更高效

== 归纳逻辑程序设计(ILP)
- 目标：完备地学习一阶规则（Horn 子句）
- 在一阶规则学习中引入了函数和逻辑表达式嵌套，具备更强的表达能力且结果可直接被逻辑程序设计语言直接使用
- 仍然以序贯覆盖方法学习规则集，一般采用自底向上策略学习单条规则，这是因为：
  - 自顶向下需要列举所有可能的候选规则；且 FOIL 在计划增益时需对规则覆盖的全部正反例技术，在引入函数和逻辑表达式嵌套后变得不可行；自顶向下策略的搜索空间对于规则长度呈指数级增长
  - 反观自底向上，对目标概念的搜索维持在样例附近的局部区域
- 最小一般泛化 (LGG)
  - 直接将一个或多个正例对应的具体事实作为厨师规则，逐步进行泛化以增加对样例的覆盖率
  - “泛化”：将覆盖率低的规则变换为覆盖率高的规则；“一般”：覆盖率尽可能高；“最小”：变换时对原规则的改动尽可能小
  - 寻找两条规则的 LGG 的步骤：
    + 找出两条规则中涉及相同谓词的文字
    + 考察谓词后括号里的项：
      - $LGG(t,t)=t$
      - $LGG(s,t), s!=t$
        - $s, t$ 不是谓词相同的项，则 $LGG(s,t)=V$，$V$ 为任意未出现过的变量
        - $s, t$ 为谓词相同的项，递归考察其括号内的项
    + 删除没有相同谓词出现的文字
      #fig("/public/assets/Courses/ML/2025-01-01-15-22-47.png", width: 60%)
    + 获取 LGG 后，将其看作单条规则加入规则集，然后进行后剪枝等优化
  - 其他基于 LGG 的 ILP 算法
    - 考虑否定文字
    - 不同的初始化选择
      - 多条特殊规则
      - 考虑所有背景知识(RLGG)
- 逆归结
  - 逻辑学中，演绎与归纳是人类认识世界的两种基本方式，机器学习属于后者
  - 演绎推理能用著名的归结原理描述，而归纳推理也有 “逆归结” 这一概念。基于归结原理，我们可将貌似复杂的逻辑规则与背景知识联系起来化繁为简；而基于逆归结，我们可基于背景知识来发明新的概念和关系
    #fig("/public/assets/Courses/ML/2025-01-01-15-38-16.png", width: 50%)
  - 置换：用项替换变量
    $ &C="色泽更深"(X,Y) and "敲声更沉"(X,Y), \ ==>^(th = {1\/X,2\/Y}) ~~~~ &C'=C th="色泽更深"(1,2) and "敲声更沉"(1,2) $
    - 复合置换：$th compose la$
    - 逆置换：$th^(-1)$
  - 合一：通过置换让两个表达式相等
    $ &A="色泽更深"(1,X), B="色泽更深"(Y,2) \ ==>^(th={2\/X,1\/Y}) ~~~~ &A th = B th = "色泽更深"(1,2) $
    - 最一般合一置换(MGU)：任意一个合法的合一置换 $th$ 都能表示为 $th_1$ 的复合置换 $th=th_1 compose la$，则称 $th_1$ 是 MGU
  - 四种完备的逆归结操作
    #grid2(
      columns: (30%, 30%),
      fig("/public/assets/Courses/ML/2025-01-01-16-04-39.png"),
      fig("/public/assets/Courses/ML/2025-01-01-16-05-00.png"),
      fig("/public/assets/Courses/ML/2025-01-01-16-05-17.png"),
      fig("/public/assets/Courses/ML/2025-01-01-16-05-31.png")
    )
  - 谓词发明：自动发明新谓词，可能对应于领域中隐含的结构、新知识
- 其他归纳逻辑程序学习方法：
  - 命题化学习
  - 逆蕴含
  - Meta-Interpretive Learning

= 强化学习
- 见 #link("http://crd2333.github.io/note/AI/Reinforce%20Learning")[我的强化学习笔记]

= 深度学习前沿
== Transformer
- 咕咕

== Diffusion Model
- 咕咕

== Mamba
- 咕咕
