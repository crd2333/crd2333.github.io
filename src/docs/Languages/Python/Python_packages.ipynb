{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 包的学习\n",
    "- 突然感觉自己平时对 python 包的探索都散落一地 / 不成系统 / 用完就忘，想在这里记录一下\n",
    "- 之所以用 Jupyter Notebook 来记录，是因为这样可以更方便地展示代码\n",
    "- 不是很想系统记录，而且这些包的基本知识不想赘述，就写一写平时见到的一些新函数吧\n",
    "- 一些记录来自 GPT，不一定准确，但是至少能跑（x\n",
    "\n",
    "也可以参考 [zhr 的笔记](https://zhroyn.github.io/MyNotes/Python/%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/OpenCVnote.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.cumsum()\n",
    "- 用于计算给定数组的累积和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  3  6 10 15]\n",
      "也就是：[1, 1+2, 1+2+3, 1+2+3+4, 1+2+3+4+5]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "numpy.cumsum(a, axis=None, dtype=None, out=None)\n",
    "参数说明：\n",
    "- a：输入的数组。\n",
    "- axis：指定计算累积和的轴的方向，默认为None，表示将数组展开并计算所有元素的累积和。\n",
    "- dtype：输出的数组的数据类型，默认为None，表示保持输入数组的数据类型。\n",
    "- out：将计算结果存储到此输出数组中。\n",
    "\"\"\"\n",
    "# 例子\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "cumulative_sum = np.cumsum(arr)\n",
    "print(cumulative_sum)\n",
    "print(\"也就是：[1, 1+2, 1+2+3, 1+2+3+4, 1+2+3+4+5]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.clip()\n",
    "- 很简单，就是剪切，限制数组的范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 3 4 4]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "clip_arr = np.clip(arr, 2, 4)\n",
    "print(clip_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.c_() 和 np.r_()\n",
    "- 用于连接两个数组，c_ 是按列连接，r_ 是按行连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = [[1 2 3 4 5 6]\n",
      " [7 8 9 1 2 3]]\n",
      "r = [[1 2 3]\n",
      " [7 8 9]\n",
      " [4 5 6]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [7, 8, 9]])\n",
    "b = np.array([[4, 5, 6], [1, 2, 3]])\n",
    "c = np.c_[a, b] # 按 col，列合并\n",
    "print(\"c =\", c)\n",
    "r = np.r_[a, b]\n",
    "print(\"r =\", r) # 按 row，行合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n",
      "[[20 21 22 23 24]]\n"
     ]
    }
   ],
   "source": [
    "# 创建一个 5x5 的数组\n",
    "a = np.arange(25).reshape((5, 5))\n",
    "print(a)\n",
    "print(a[4:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.expand_dims() 和 np.squeeze()\n",
    "- 与 pytorch 中的 unsqueeze() 和 squeeze() 类似，用于扩展和压缩维度，用法也类似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.sum()\n",
    "- 很简单的求和函数，不简单之处在于 axis(dim) 的理解，在此为例展开讲解坐标理解法，如图\n",
    "\n",
    "    ![image.png](https://s2.loli.net/2024/02/06/xCYrnWzX4SotZeG.png)\n",
    "  - 对哪个 axis 求和，即对哪个坐标轴进行压缩\n",
    "- `keepdims=True` 能够保持维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10],\n",
      "         [11, 12, 13, 14, 15]],\n",
      "\n",
      "        [[16, 17, 18, 19, 20],\n",
      "         [21, 22, 23, 24, 25],\n",
      "         [26, 27, 28, 29, 30]]])\n",
      "tensor([[17, 19, 21, 23, 25],\n",
      "        [27, 29, 31, 33, 35],\n",
      "        [37, 39, 41, 43, 45]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 31).reshape(2, 3, 5)\n",
    "print(a)\n",
    "b = a.sum(axis=0)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.max() & troch.min()\n",
    "- PyTorch 的 `max()` 和 `min()` 与 NumPy 有点不一样\n",
    "  - 最后需要加 `[0]` 或 `.values` 返回值\n",
    "  - 加 `[1]` 或 `.indices` 返回索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4,  5],\n",
      "         [ 6,  7,  8,  9, 10],\n",
      "         [11, 12, 13, 14, 15]],\n",
      "\n",
      "        [[16, 17, 18, 19, 20],\n",
      "         [21, 22, 23, 24, 25],\n",
      "         [26, 27, 28, 29, 30]]])\n",
      "\n",
      "torch.return_types.max(\n",
      "values=tensor([[11, 12, 13, 14, 15],\n",
      "        [26, 27, 28, 29, 30]]),\n",
      "indices=tensor([[2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2]]))\n",
      "\n",
      "tensor([[11, 12, 13, 14, 15],\n",
      "        [26, 27, 28, 29, 30]])\n",
      "\n",
      "tensor([[11, 12, 13, 14, 15],\n",
      "        [26, 27, 28, 29, 30]])\n",
      "\n",
      "tensor([[2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2]])\n",
      "\n",
      "tensor([[2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1, 31).reshape(2, 3, 5)\n",
    "print(a)\n",
    "print()\n",
    "print(a.max(dim=1))\n",
    "print()\n",
    "print(a.max(dim=1)[0])\n",
    "print()\n",
    "print(a.max(dim=1).values)\n",
    "print()\n",
    "print(a.max(dim=1)[1])\n",
    "print()\n",
    "print(a.max(dim=1).indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.unsqueeze() & torch.squeeze()\n",
    "- `unsqueeze()` 函数起升维的作用，参数 `dim` 表示在哪个地方加一个维度\n",
    "  - 例如，shape 为 `(x,y,z)` 的张量在 `dim=0` 加一个维度就变成 `(1,x,y,z)`\n",
    "  - 不过，`unsqueeze()` 也可以通过 `b = a[None, :, :]` 的方式实现 `shape (x, y)` 变为 `shape (1, x, y)`\n",
    "- `squeeze()` 函数则相反，如果不指定维度，则删除所有 shape 为 $1$ 的维度，否则删除指定维度（需要能够删除，即 shape 为 $1$）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "torch.Size([6])\n",
      "tensor([[0, 1, 2, 3, 4, 5]])\n",
      "torch.Size([1, 6])\n",
      "tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "input=torch.arange(0,6)\n",
    "print(input)\n",
    "print(input.shape)\n",
    "print(input.unsqueeze(0))\n",
    "print(input.unsqueeze(0).shape)\n",
    "print(input.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.item() 和 torch.tolist()\n",
    "- 分别是转换为标量和转换为 python 内置列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[1, 2], [3, 4]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5])\n",
    "num = x.item()\n",
    "print(num)  # 输出: 5\n",
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "lst = x.tolist()\n",
    "print(lst)  # 输出: [[1, 2], [3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.gather()\n",
    "- 作用：沿着由 dim 指定的轴收集数值\n",
    "- 有点点复杂，看例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 2.1000, 2.2000, 2.3000],\n",
      "        [1.0000, 1.1000, 1.2000, 1.3000],\n",
      "        [0.0000, 0.1000, 0.2000, 0.3000],\n",
      "        [0.0000, 1.1000, 2.2000, 0.3000]])\n",
      "tensor([[0.2000, 0.2000, 0.2000, 0.2000],\n",
      "        [1.1000, 1.1000, 1.1000, 1.1000],\n",
      "        [2.0000, 2.1000, 2.2000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([[0.0, 0.1, 0.2, 0.3],\n",
    "                      [1.0, 1.1, 1.2, 1.3],\n",
    "                      [2.0, 2.1, 2.2, 2.3]]) # shape [3,4]\n",
    "length = torch.LongTensor([[2,2,2,2],\n",
    "                           [1,1,1,1],\n",
    "                           [0,0,0,0],\n",
    "                           [0,1,2,0]]) # shape [4,4]\n",
    "out = torch.gather(input, dim=0, index=length)\n",
    "print(out)\n",
    "\n",
    "input = torch.tensor([[0.0, 0.1, 0.2, 0.3],\n",
    "                      [1.0, 1.1, 1.2, 1.3],\n",
    "                      [2.0, 2.1, 2.2, 2.3]]) # shape [3,4]\n",
    "length = torch.LongTensor([[2,2,2,2],\n",
    "                           [1,1,1,1],\n",
    "                           [0,1,2,0]]) # shape [3,4]\n",
    "out = torch.gather(input, dim=1, index=length)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.expand() & torch.repeat()\n",
    "- `expand()` 是扩展到指定维度，但内存上不会拷贝\n",
    "- `repeat()` 是指定复制维度几次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [1, 2, 3]]) \n",
      " tensor([[1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "\n",
      " tensor([[-1,  2,  3],\n",
      "        [-1,  2,  3]]) \n",
      " tensor([[-1,  2,  3],\n",
      "        [ 1,  2,  3]])\n",
      "tensor([[[ 1.6970, -0.1985, -0.5661],\n",
      "         [-1.5805, -0.8865, -0.5352]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = x.repeat(2, 1)\n",
    "x = x.expand(2, 3)\n",
    "print(x, '\\n', y)\n",
    "x[0][0] = -1 # both x[0][0] and x[1][0] changed\n",
    "y[0][0] = -1 # only y[0][0] changed\n",
    "print('\\n', x, '\\n', y)\n",
    "\n",
    "a = torch.randn(1, 2, 3)\n",
    "print(a)\n",
    "# a = a.expand(2, 3, 3) # RuntimeError: The expanded size of the tensor must match the existing size  at non-singleton dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.InstanceNorm()\n",
    "- 可以参考 [nn.InstanceNorm2d 和 nn.BatchNorm2d比较](https://blog.csdn.net/qq_36892712/article/details/132131106)\n",
    "- 对每个样本（实例）的特征进行归一化。适用于每个样本的特征分布不同的情况，如图像风格转换等任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.BatchNorm2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LayerNorm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "- `pandas` 软件包是 Python 中常用的数据分析工具中，pandas 可以与 tensor 兼容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.loc() 和 pd.iloc()\n",
    "- 用于选取行和列，前者是用标签，后者是用 index\n",
    "- 如果是取单个元素，可以替换为 pd.at() 和 pd.iat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a   -0.348153\n",
      "b    0.428440\n",
      "c    0.207352\n",
      "d    0.719478\n",
      "e    1.064853\n",
      "f    0.300518\n",
      "dtype: float64\n",
      "0.4284403322970918\n",
      "e    1.064853\n",
      "f    0.300518\n",
      "dtype: float64\n",
      "b    0.42844\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s1 = pd.Series(np.random.randn(6), index=list('abcdef'))\n",
    "print(s1)\n",
    "print(s1.loc['b'])\n",
    "print(s1.loc['e':'f']) # 标签切片，注意包含末端！\n",
    "print(s1.iloc[1:2]) # index 切片，同 python indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.get_dummies()\n",
    "- 将信息转换为 one-hot 编码的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color class\n",
      "0  green     A\n",
      "1    red     B\n",
      "2   blue     A\n",
      "   color_blue  color_green  color_red  class_A  class_B\n",
      "0       False         True      False     True    False\n",
      "1       False        False       True    False     True\n",
      "2        True        False      False     True    False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "            ['green' , 'A'],\n",
    "            ['red'   , 'B'],\n",
    "            ['blue'  , 'A']])\n",
    "df.columns = ['color',  'class']\n",
    "\n",
    "print(df)\n",
    "df = pd.get_dummies(df) # 也可以指定某一列 pd.get_dummies(df.color)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
